{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BKBKlaassen/Gr8_ModelsForLanguageProcessing_assignments/blob/main/Group_8_M4LP_Assignment_2_(2026).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zydk5m0FpaKT"
      },
      "source": [
        "## Assignment 2\n",
        "\n",
        "This is the complete Assignment 2. You are asked to train and test linear and logistic regression models and access lexical resources."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Contributions</font>\n",
        "\n",
        "\n",
        "* group number: 8\n",
        "* Bjorn Klaassen, Noah de Jonge\n",
        "* all assignments done together:1,2,3, Bjorn: 4, noah: 6"
      ],
      "metadata": {
        "id": "8rvH77dcj-2Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ledaEclUpvzT"
      },
      "source": [
        "To start the assignment, import prerequisite packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bRh6vltQpvTn"
      },
      "outputs": [],
      "source": [
        "import nltk,sklearn\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import collections, itertools\n",
        "import more_itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe word embeddings will be loaded through gensim package:"
      ],
      "metadata": {
        "id": "q1Gjwmay1urI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is all you need. **Do not import anything else at other points** except where suggested.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J45SbnKlSIbx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKO1jxm3pv93"
      },
      "source": [
        "# 2.1 Load GloVe word embedding model\n",
        "\n",
        "GloVe contains _static_ word embeddings. This means that the vector is assigned to word types and does not vary in different contexts or for different word senses. Pretrained GloVe word embedding models exist in different sizes. For the purpose of the exercise, we will use the smallest GloVe vectors with 50 dimensions. First, let's download the vectors and load the embedding model as `glove`. This may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RpbzSKOiuYge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5ed897-ac50-44f0-f8a9-21a1024df95c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "metadata": {
        "id": "z4GPth-uIwMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb4adfc7-cc44-4bc5-cea5-6476434ee663"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another download workaround**. Sometimes StanfordNLP server is down and the embeddings don't load. In this case, you can obtain them from other sources. For example, download the embeddings from Kaggle (https://www.kaggle.com/datasets/rtatman/glove-global-vectors-for-word-representation?select=glove.6B.50d.txt), unzip the file and upoad it to the Colab working directory (left panel on Colab). Then uncomment and run:"
      ],
      "metadata": {
        "id": "QCFjiiY9FFiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from gensim.models import KeyedVectors\n",
        "#glove = KeyedVectors.load_word2vec_format('glove.6B.50d.txt', binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "-nvSK6__CQ1V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPoOZtlxqII4"
      },
      "source": [
        "The exercises below require understanding of gensim vector spaces. You can learn some basics from a tutorial on [word2vec](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html), which is an alternative to GloVe. For example, you will see in the tutorial that gensim word2vec has `wv.index_to_key` and `wv.key_to_index` attributes. By using a similar attribute of `glove`, we can count how many words the GloVe embeddings contain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4JMWM-iTqHNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf11648-146b-42c2-e36a-32a16b96a453"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(glove.key_to_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check if particular orthographic words have vectors in `glove`.\n",
        "\n",
        "**Exercise**. Check if strings 'asdfdfasd', \"catc\", \"cact\", and \"cat\" have a glove vector, and print the resuts as truth values."
      ],
      "metadata": {
        "id": "6iaJetpi504A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "stringList = ['asdfdfasd', \"catc\", \"cact\",\"cat\" ]\n",
        "for string in stringList:\n",
        "  try:\n",
        "    glove[string]\n",
        "    print(True)\n",
        "  except KeyError:\n",
        "    print(False)\n",
        "\n"
      ],
      "metadata": {
        "id": "jfmuq9kNyRhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1289c1-9622-4f46-f8ef-e0614da6994b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkVR4dXbqOSY"
      },
      "source": [
        "**Exercise**. What is the vector of _cat_? Print it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0-EQf6-dqN_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df1d60e-6abf-4a1d-81f4-06384e66558c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.45281  -0.50108  -0.53714  -0.015697  0.22191   0.54602  -0.67301\n",
            " -0.6891    0.63493  -0.19726   0.33685   0.7735    0.90094   0.38488\n",
            "  0.38367   0.2657   -0.08057   0.61089  -1.2894   -0.22313  -0.61578\n",
            "  0.21697   0.35614   0.44499   0.60885  -1.1633   -1.1579    0.36118\n",
            "  0.10466  -0.78325   1.4352    0.18629  -0.26112   0.83275  -0.23123\n",
            "  0.32481   0.14485  -0.44552   0.33497  -0.95946  -0.097479  0.48138\n",
            " -0.43352   0.69455   0.91043  -0.28173   0.41637  -1.2609    0.71278\n",
            "  0.23782 ]\n"
          ]
        }
      ],
      "source": [
        "#your code here\n",
        "cat_vec = glove[\"cat\"]\n",
        "print(cat_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Which dimensions of vectors for \"cat\" and \"dog\" are similar, i.e. different by no more than 0.25? Print their indices. How many such dimensions are there? What is the proportion of similar dimensions out of all dimensions?\n",
        "\n"
      ],
      "metadata": {
        "id": "SznYrJv4KVOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n",
        "dog_vec = glove[\"dog\"]\n",
        "\n",
        "similar_dimensions = []\n",
        "\n",
        "for index in range(0,len(dog_vec)):\n",
        "  if(abs(dog_vec[index]-cat_vec[index]) <= 0.25):\n",
        "    similar_dimensions.append(index)\n",
        "\n",
        "print(\"Indices of similar dimensions:\",similar_dimensions)\n",
        "print(\"Number of similar dimensions:\", len(similar_dimensions))\n",
        "print(\"Proportion of similar dimensions:\",len(similar_dimensions), \"/\", len(dog_vec))\n"
      ],
      "metadata": {
        "id": "KMkVBIXpOfDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55097a8-d9d8-40df-959a-fdf5c9a98f50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of similar dimensions: [1, 2, 5, 11, 13, 14, 18, 20, 21, 24, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 48, 49]\n",
            "Number of similar dimensions: 29\n",
            "Proportion of similar dimensions: 29 / 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Compute the cosine of vectors for _cat_ and _dog_ using a gensim built-in function."
      ],
      "metadata": {
        "id": "Aqh_sjbD2i_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n",
        "print(glove.similarity(\"cat\",\"dog\"))\n"
      ],
      "metadata": {
        "id": "-yoE2TmL2N4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1e7b15-e49e-4288-945d-727faca8f5b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9218005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byR4o0uZuYU0"
      },
      "source": [
        "# 2.2 Linear regression: Concreteness prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MudXBEHPqZQR"
      },
      "source": [
        "Obtain concreteness ratings from the paper\n",
        "\n",
        "Brysbaert, M., Warriner, A., & Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. BEHAVIOR RESEARCH METHODS, 46 (3), 904–911. https://doi.org/10.3758/s13428-013-0403-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Cpty1jvvqZxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979ec65d-d045-41bb-a053-662b730a7356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-10 08:26:28--  https://raw.githubusercontent.com/ArtsEngine/concreteness/master/Concreteness_ratings_Brysbaert_et_al_BRM.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1646191 (1.6M) [text/plain]\n",
            "Saving to: ‘Concreteness_ratings_Brysbaert_et_al_BRM.txt’\n",
            "\n",
            "Concreteness_rating 100%[===================>]   1.57M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2026-02-10 08:26:28 (24.5 MB/s) - ‘Concreteness_ratings_Brysbaert_et_al_BRM.txt’ saved [1646191/1646191]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/ArtsEngine/concreteness/master/Concreteness_ratings_Brysbaert_et_al_BRM.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTWFbrn6q1gE"
      },
      "source": [
        "This is a tab-separated file with a header. Structured data like this can be conveniently read via DictReader class from csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koGwR3hfrNR_"
      },
      "source": [
        "Using DictReader, we create lists ```concreteness_words``` and ```concreteness_scores``` of words in the concreteness ratings file that have a GloVe vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YwSaCcHBrhjf"
      },
      "outputs": [],
      "source": [
        "concreteness_words=[]\n",
        "concreteness_scores=[]\n",
        "with open(\"Concreteness_ratings_Brysbaert_et_al_BRM.txt\",'r') as concfile:\n",
        "  read_tsv = csv.DictReader(concfile, delimiter=\"\\t\")\n",
        "  for row in read_tsv:\n",
        "    word=row[\"Word\"]\n",
        "    if word in glove:\n",
        "      concreteness_words.append(word)\n",
        "      concreteness_scores.append(float(row[\"Conc.M\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many words ended up in your concreteness dataset?"
      ],
      "metadata": {
        "id": "0MQ7uWgvQxL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(concreteness_words))"
      ],
      "metadata": {
        "id": "_Gmj9W9VQAKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69f8d2f-fc26-439c-b39c-211aa8c24827"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDKmvggQrq9X"
      },
      "source": [
        "We can now create train and test partitions of concreteness data (conc_words_train, conc_words_test, conc_scores_train, conc_scores_test) with 10% test and 90% training split. Do not use random state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tCoOZ32trriI"
      },
      "outputs": [],
      "source": [
        "conc_words_train, conc_words_test, conc_scores_train, conc_scores_test = train_test_split(concreteness_words,concreteness_scores,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKo12DqNr57Z"
      },
      "source": [
        "Convert data to torch tensor format to use in a regression model (ignore UserWarning):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IExC7ts2r6WF"
      },
      "outputs": [],
      "source": [
        "conc_vectors_train = torch.from_numpy(np.array([glove[word] for word in conc_words_train]))\n",
        "conc_vectors_test = torch.from_numpy(np.array([glove[word] for word in conc_words_test]))\n",
        "conc_scores_train = torch.tensor(conc_scores_train, dtype=torch.float32)\n",
        "conc_scores_test = torch.tensor(conc_scores_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise** Explain in a couple of sentences what the second and third lines of code in the above cell does.\n",
        "\n",
        "The second line assigns a collection of arrays that we split previously for testing, which are converted to the appropriate data-structure for pyTorch, to the variable conc_vector_test.\n",
        "\n",
        "The third line converts the scores for the training data into a pyTorch tensor (vector), and assigns it to conc_scores_train."
      ],
      "metadata": {
        "id": "RbIFJmZ7Vy8G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA41kZdKsKgR"
      },
      "source": [
        "Now we can define linear regression model in pyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z1QduXYcsOj3"
      },
      "outputs": [],
      "source": [
        "class Regression(torch.nn.Module):\n",
        "     def __init__(self, input_dim, output_dim):\n",
        "         super(Regression, self).__init__()\n",
        "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "     def forward(self, x):\n",
        "         outputs = self.linear(x)\n",
        "         return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Study pyTorch documentation at\n",
        "\n",
        "https://docs.pytorch.org/tutorials/index.html\n",
        "\n",
        "to understand the definition of the regression class. Explain each line of the class definition above. For example, line 3 can be explained as follows:\n",
        "\n",
        "Line 3 `super(Regression, self).__init__()` initializes a new Regression model as an instance of the parent class `torch.nn.Module`\n",
        "\n",
        "Now explain all other lines of the class code.\n",
        "\n",
        "Line 1 `class Regression(torch.nn.Module):` Defines the class name of the new model:\"Regression\" which inherits from `torch.nn.Module.`\n",
        "\n",
        "Line 2 `def __init__(self, input_dim, output_dim):` this method is used to initialize a new instance of the model, it defines the layers of the network, it takes in the size of the input dimension and the size of the output dimension.\n",
        "\n",
        "Line 4 `self.linear = torch.nn.Linear(input_dim, output_dim)` Applies an affine linear transformation to the incoming data using the size of each input sample, and the size  of each output sample, as defined by input_dim and output_dim, repectively.\n",
        "\n",
        "Line 5 `def forward(self, x):` this method is specifies how data will pass through the network, it can be used to implement operations on the input data.\n",
        "\n",
        "Line 6 `outputs = self.linear(x)` applies the linear transformation through the network as defined in Line 4 and stores the result in output.\n",
        "\n",
        "Line 7 `return outputs` returns the result of the linear transformation that was stored in outputs."
      ],
      "metadata": {
        "id": "a2Hx3FTn7TWc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGGf2CJksYPp"
      },
      "source": [
        "A specific linear regression model can have the input dimensionality of our word embeddings and 1-dimensional input (the concretenss score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glovedim = 50"
      ],
      "metadata": {
        "id": "-A5qxOl3K15t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YfQIuGBqsXoG"
      },
      "outputs": [],
      "source": [
        "model = Regression(glovedim,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQcK2QCqsy4P"
      },
      "source": [
        "To train the model, we need a loss function and an optimiser, including the learning rate parameter. We choose Mean Square Error loss (suitable for learning linear regression) and Stochastic Gradient Descent method with the learning rate of 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LJHqQcuaMcNL"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KIuhn2FeNCph"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How PyTorch learns from data**\n",
        "\n",
        "Training a neural network means adjusting its parameters (weights and biases) so that its predictions get closer to the true values. PyTorch does this in four steps, repeated each epoch:\n",
        "\n",
        "- **Forward pass**: Input data flows through the model to produce predictions. Behind the scenes, PyTorch builds a computation graph — a record of every operation performed on the data.\n",
        "- **Loss calculation**: We measure how wrong the predictions are using a loss function (here, mean squared error).\n",
        "- **Backward pass** (`loss.backward()`): PyTorch walks backward through the computation graph, calculating gradients — these tell us how much each parameter contributed to the error, and in which direction it should change.\n",
        "- **Parameter update** (`optimizer.step()`): The optimizer adjusts each parameter by a small amount in the direction that reduces the loss.\n",
        "\n",
        "We call `zero_grad()` at the start because PyTorch accumulates gradients by default — without clearing them, gradients from previous epochs would mix with the current ones.\n",
        "\n",
        "A **computation graph** represents how outputs are computed from inputs, step by step. For training purposes, the inputs are model parameters (`linear.weight` and `linear.bias`) and the output is the loss value. A computation graph can be visualized in a diagram like:\n",
        "\n",
        "```\n",
        "  ┌───────────────────────┐\n",
        "  │   linear.weight       │\n",
        "  │   linear.bias         │\n",
        "  └───────────────────────┘\n",
        "              │\n",
        "              ▼\n",
        "           (Addmm)\n",
        "              │\n",
        "              ▼\n",
        "          (MseLoss)\n",
        "              │\n",
        "              ▼\n",
        "            loss\n",
        "            \n"
      ],
      "metadata": {
        "id": "O85a759PJxIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The computation graph (simplified for expository purposes) shows what PyTorch tracks: learnable parameters of the linear layer (weights and bias) udergo matrix multiplication with data and bias addition, then feed into the loss function.\n",
        "\n",
        "Why does the computation graph matter? To train the model, we need to know: \"If I nudge a weight slightly, how much does the loss change?\" When we call `loss.backward()`, PyTorch traverses this graph in reverse, from loss back to the parameters, computing gradients along the way. These gradients tell the optimizer how to adjust each parameter to reduce the loss."
      ],
      "metadata": {
        "id": "SVCOLO13NLO6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjjMEoVvtSc0"
      },
      "source": [
        "We can now train our linear regression model using gradient descent.\n",
        "\n",
        "**Exercise**. Every 5 training steps, evaluate the model, printing out loss and accuracy for the training and test sets. Calculate the accuracy as the percentage of examples where the predicted score of the model differs from the correct score by less than 1. The training may take a minute or so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uDQGZSxWsyPH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270,
          "referenced_widgets": [
            "978f8dc2bfe6441dbc856a5f8bc02730",
            "0c2c377df9e84279a56baef188639811",
            "67a2a90a9c354b48a9dda2de483a9f58",
            "95be26cc875240bf8554b8003d1d7732",
            "2e06529c9028469d96846b8030ed7967",
            "3477d0091db743e2ae0b25fd22908ef1",
            "b8a4cba0ba7b4a48b27e5268a79e7ce3",
            "9f0ad5beb9334a0dbe4a3d9ef9d94bdf",
            "8b474206b7424c54ab4421beac6e92dd",
            "4d982ea804184cda925022f0c9500c6f",
            "96058744d7574566bede7d6b098a29d3"
          ]
        },
        "outputId": "47b831fe-ef17-44d7-859b-67786bc10444"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "978f8dc2bfe6441dbc856a5f8bc02730"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:\n",
            "Train loss: 1.5388516187667847, Train accuracy: 0.6019819974899292\n",
            "Test loss: 1.5806013345718384, Test accuracy: 0.591714084148407\n",
            "Epoch 10:\n",
            "Train loss: 1.0533684492111206, Train accuracy: 0.6877635717391968\n",
            "Test loss: 1.0835115909576416, Test accuracy: 0.6850094795227051\n",
            "Epoch 15:\n",
            "Train loss: 0.8463487029075623, Train accuracy: 0.73573237657547\n",
            "Test loss: 0.8661755919456482, Test accuracy: 0.7267552018165588\n",
            "Epoch 20:\n",
            "Train loss: 0.7285656332969666, Train accuracy: 0.7656733393669128\n",
            "Test loss: 0.7406714558601379, Test accuracy: 0.761543333530426\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "losses_test = []\n",
        "Iterations = []\n",
        "epochs=20\n",
        "tolerance = 1\n",
        "#after defining parameters, we train the model several times on the same data; each iteration is an epoch:\n",
        "for epoch in trange(epochs, desc='Training Epochs'):\n",
        "    x = conc_vectors_train\n",
        "    scores = conc_scores_train\n",
        "    #clear gradients from previous epoch (PyTorch accumulates them by default)\n",
        "    optimizer.zero_grad()\n",
        "    #here we pass the word vectors from the training set, obtaining regression model's predicted outputs:\n",
        "    outputs = model(x)\n",
        "    #compute the loss: how far are predictions from true scores?\n",
        "    loss = criterion(torch.squeeze(outputs), scores)\n",
        "    #compute gradients: how should each parameter change to reduce the loss?\n",
        "    loss.backward()\n",
        "    #update model parameters using the computed gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    #Now, every 5 epochs we can evaluate how the model performs on the data\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        #we don't compute gradients as the model is only evaluated and not updated\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            predictions = torch.squeeze(model(x))\n",
        "            loss = criterion(predictions, scores)\n",
        "            accuracy = (torch.abs(predictions - scores) <= tolerance).float().mean().item()\n",
        "            testX = conc_vectors_test\n",
        "            testScores = conc_scores_test\n",
        "            testPredictions = torch.squeeze(model(testX))\n",
        "            testLoss = criterion(testPredictions, testScores)\n",
        "            testAccuracy = (torch.abs(testPredictions - testScores) <= tolerance).float().mean().item()\n",
        "            print(f\"Epoch {epoch + 1}:\")\n",
        "            print(f\"Train loss: {loss}, Train accuracy: {accuracy}\")\n",
        "            print(f\"Test loss: {testLoss}, Test accuracy: {testAccuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The real computation graph used by pyTorch here is a little more complex than the schematic illustration we gave above; if you want to visualize it (using the familiar `graphviz` as the underlying engine), uncomment and run:"
      ],
      "metadata": {
        "id": "s2amIG-nNIyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torchviz\n",
        "#from torchviz import make_dot\n",
        "#make_dot(loss, params=dict(model.named_parameters()), show_attrs=False, show_saved=False)"
      ],
      "metadata": {
        "id": "ePPifiwLI5yM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <details>\n",
        "<summary><b>Click to see detailed explanation</b></summary>\n",
        "\n",
        "**Understanding the computation graph**\n",
        "\n",
        "The `torchviz` diagram shows the following nodes:\n",
        "\n",
        "| Node | What it is |\n",
        "|------|------------|\n",
        "| `linear.weight (1, 50)` | The learnable weight matrix of our linear layer: 50 input dimensions mapped to 1 output |\n",
        "| `linear.bias (1)` | The learnable bias term of our linear layer: a single value added to the output |\n",
        "| `AccumulateGrad` | A marker indicating \"this is a leaf node where gradients will be accumulated\" — appears next to each learnable parameter |\n",
        "| `TBackward0` | The backward operation for transpose (`T`): PyTorch transposes the weight matrix during the linear calculation |\n",
        "| `AddmmBackward0` | The backward operation for `addmm` (add + matrix multiply). This computes `bias + input @ weight.T`, which is what `nn.Linear` does internally |\n",
        "| `SqueezeBackward0` | The backward operation for `squeeze()`: shape adjustment from `(n, 1)` to `(n,)` |\n",
        "| `MseLossBackward0` | The backward operation for mean squared error loss |\n",
        "\n",
        "The \"Backward\" suffix indicates these are the *reverse* operations that PyTorch will use during backpropagation. The graph is built during the forward pass, but it stores the operations needed to compute gradients in reverse.\n",
        "\n",
        "Reading from bottom to top, the forward pass was:\n",
        "1. Take `linear.weight` and transpose it (`TBackward0`)\n",
        "2. Multiply input by transposed weights and add bias (`AddmmBackward0`)\n",
        "3. Squeeze the output shape (`SqueezeBackward0`)\n",
        "4. Compute MSE loss against target scores (`MseLossBackward0`)\n",
        "\n",
        "When we call `loss.backward()`, PyTorch traverses from top to bottom, computing gradients at each step until it reaches the `AccumulateGrad` nodes, where gradients are stored in `linear.weight.grad` and `linear.bias.grad`.\n",
        "</details>"
      ],
      "metadata": {
        "id": "y4x3sWCgOU1w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SJ3qAwKfDov"
      },
      "source": [
        "**Exercise**. What are the predicted concreteness score of the nouns _logarithm_ and _mouse_? Print them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "z76FnkTpAeO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e906608-05db-4fb1-be5e-7a3f12dda27b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the scale from 1 to 5, our trained regression model predicts the concreteness scoere of 'logarithm' to be 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2892682298.py:4: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  return round(float(predicted_score[0]), 0)\n"
          ]
        }
      ],
      "source": [
        "def predicted_concreteness(wd):\n",
        "  model.eval()\n",
        "  predicted_score =  model(torch.from_numpy(np.array(glove[wd])))\n",
        "  return round(float(predicted_score[0]), 0)\n",
        "\n",
        "print(\"On the scale from 1 to 5, our trained regression model predicts the concreteness score of 'logarithm' to be\",predicted_concreteness(\"logarithm\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wu2jvBh5fAmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b912d58-8799-4303-af94-af6a8480f89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the scale from 1 to 5, our trained regression model predicts the concreteness scoere of 'mouse' to be 5.0\n"
          ]
        }
      ],
      "source": [
        "print(\"On the scale from 1 to 5, our trained regression model predicts the concreteness score of 'mouse' to be\",predicted_concreteness(\"mouse\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6CTQkPAviBj"
      },
      "source": [
        "# 2.3. Create a dataset of WordNet supersenses for words that have GloVe vectors.\n",
        "\n",
        "First, download the WordNet database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0_TbA4Pfv9v5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4e1c9b-8091-43ed-ea04-d1ff198ab960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can read documentation on object types in WordNet, for example by invoking the types:"
      ],
      "metadata": {
        "id": "gPVFTv6lngfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.reader.wordnet.Lemma"
      ],
      "metadata": {
        "id": "uLnPl63pnK-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "90c93dab-9435-44d9-8ae1-d39760afd250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.corpus.reader.wordnet.Lemma"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.corpus.reader.wordnet.Lemma</b><br/>def __init__(wordnet_corpus_reader, synset, name, lexname_index, lex_id, syntactic_marker)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py</a>The lexical entry for a single morphological form of a\n",
              "sense-disambiguated word.\n",
              "\n",
              "Create a Lemma from a &quot;&lt;word&gt;.&lt;pos&gt;.&lt;number&gt;.&lt;lemma&gt;&quot; string where:\n",
              "&lt;word&gt; is the morphological stem identifying the synset\n",
              "&lt;pos&gt; is one of the module attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
              "&lt;number&gt; is the sense number, counting from 0.\n",
              "&lt;lemma&gt; is the morphological form of interest\n",
              "\n",
              "Note that &lt;word&gt; and &lt;lemma&gt; can be different, e.g. the Synset\n",
              "&#x27;salt.n.03&#x27; has the Lemmas &#x27;salt.n.03.salt&#x27;, &#x27;salt.n.03.saltiness&#x27; and\n",
              "&#x27;salt.n.03.salinity&#x27;.\n",
              "\n",
              "Lemma attributes, accessible via methods with the same name:\n",
              "\n",
              "- name: The canonical name of this lemma.\n",
              "- synset: The synset that this lemma belongs to.\n",
              "- syntactic_marker: For adjectives, the WordNet string identifying the\n",
              "  syntactic position relative modified noun. See:\n",
              "  https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "  For all other parts of speech, this attribute is None.\n",
              "- count: The frequency of this lemma in wordnet.\n",
              "\n",
              "Lemma methods:\n",
              "\n",
              "Lemmas have the following methods for retrieving related Lemmas. They\n",
              "correspond to the names for the pointer symbols defined here:\n",
              "https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "These methods all return lists of Lemmas:\n",
              "\n",
              "- antonyms\n",
              "- hypernyms, instance_hypernyms\n",
              "- hyponyms, instance_hyponyms\n",
              "- member_holonyms, substance_holonyms, part_holonyms\n",
              "- member_meronyms, substance_meronyms, part_meronyms\n",
              "- topic_domains, region_domains, usage_domains\n",
              "- attributes\n",
              "- derivationally_related_forms\n",
              "- entailments\n",
              "- causes\n",
              "- also_sees\n",
              "- verb_groups\n",
              "- similar_tos\n",
              "- pertainyms</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 219);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.reader.wordnet.Synset"
      ],
      "metadata": {
        "id": "e5PBoC8invpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d14c4168-14f3-49da-b2a6-9873977998e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.corpus.reader.wordnet.Synset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.corpus.reader.wordnet.Synset</b><br/>def __init__(wordnet_corpus_reader)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py</a>Create a Synset from a &quot;&lt;lemma&gt;.&lt;pos&gt;.&lt;number&gt;&quot; string where:\n",
              "&lt;lemma&gt; is the word&#x27;s morphological stem\n",
              "&lt;pos&gt; is one of the module attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
              "&lt;number&gt; is the sense number, counting from 0.\n",
              "\n",
              "Synset attributes, accessible via methods with the same name:\n",
              "\n",
              "- name: The canonical name of this synset, formed using the first lemma\n",
              "  of this synset. Note that this may be different from the name\n",
              "  passed to the constructor if that string used a different lemma to\n",
              "  identify the synset.\n",
              "- pos: The synset&#x27;s part of speech, matching one of the module level\n",
              "  attributes ADJ, ADJ_SAT, ADV, NOUN or VERB.\n",
              "- lemmas: A list of the Lemma objects for this synset.\n",
              "- definition: The definition for this synset.\n",
              "- examples: A list of example strings for this synset.\n",
              "- offset: The offset in the WordNet dict file of this synset.\n",
              "- lexname: The name of the lexicographer file containing this synset.\n",
              "\n",
              "Synset methods:\n",
              "\n",
              "Synsets have the following methods for retrieving related Synsets.\n",
              "They correspond to the names for the pointer symbols defined here:\n",
              "https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "These methods all return lists of Synsets.\n",
              "\n",
              "- hypernyms, instance_hypernyms\n",
              "- hyponyms, instance_hyponyms\n",
              "- member_holonyms, substance_holonyms, part_holonyms\n",
              "- member_meronyms, substance_meronyms, part_meronyms\n",
              "- attributes\n",
              "- entailments\n",
              "- causes\n",
              "- also_sees\n",
              "- verb_groups\n",
              "- similar_tos\n",
              "\n",
              "Additionally, Synsets support the following methods specific to the\n",
              "hypernym relation:\n",
              "\n",
              "- root_hypernyms\n",
              "- common_hypernyms\n",
              "- lowest_common_hypernyms\n",
              "\n",
              "Note that Synsets do not support the following relations because\n",
              "these are defined by WordNet as lexical relations:\n",
              "\n",
              "- antonyms\n",
              "- derivationally_related_forms\n",
              "- pertainyms</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 351);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Now, retrieve the first lemma corresponding to the adjective _dry_ as `d`:"
      ],
      "metadata": {
        "id": "_nCIbS2Zn7WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d= wn.lemma(\"dry.a.01.dry\")"
      ],
      "metadata": {
        "id": "FzpyC3J9mYXp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. What lemmas belong to the same SynSet? Retrieve the list."
      ],
      "metadata": {
        "id": "dhp5dHaeodHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d.synset().lemmas()"
      ],
      "metadata": {
        "id": "V29C-0zinUI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b47631-7a70-4b19-8652-25b49ff7cf21"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('dry.a.01.dry')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Define function `ant_freq` that returns the frequency of (the first) antonym of a lemma.\n"
      ],
      "metadata": {
        "id": "0_tAe2v8ojJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ant_freq(x):\n",
        "  return x.antonyms()[0].count()"
      ],
      "metadata": {
        "id": "wrtQvLOgmzd5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply `ant_freq` to `d`. This will output the frequency of _wet_."
      ],
      "metadata": {
        "id": "W63hTqccovBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ant_freq(d)"
      ],
      "metadata": {
        "id": "xbWZj8cqm3wR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0778ed57-eb79-4146-e183-96e6462bdd39"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9UHFcCUwO_4"
      },
      "source": [
        "**Exercise**. Now, create a dataset that includes for each word in WordNet that has a GloVe vector the lexicographic file (supersense) of its first synset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "C43EVE68ytWG"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "\n",
        "wn_words = [w for w in wn.all_lemma_names() if w in glove]\n",
        "wn_supersenses = []\n",
        "seen = []\n",
        "for w in wn_words:\n",
        "  s = wn.synsets(w)[0].lexname()\n",
        "  if s in seen:\n",
        "    wn_supersenses.append(seen.index(s))\n",
        "  else:\n",
        "    wn_supersenses.append(len(seen))\n",
        "    seen.append(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHXhjXvjyt18"
      },
      "source": [
        "Split the dataset into train and test partitions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "1lrFM_48yW83"
      },
      "outputs": [],
      "source": [
        "wn_words_train, wn_words_test, wn_supersenses_train, wn_supersenses_test = train_test_split(wn_words,wn_supersenses,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0tWUqkugfe"
      },
      "source": [
        "# 2.4. Logistic regression: word class prediction.\n",
        "\n",
        "Now we can address a classification task. Define a (multinomial) regression model using softmax, choose a loss function and an optimizer for it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. We will need to set the number of classes for classification. Estimate `num_classes`prior to initializing the model. Use `wn_supersenses`."
      ],
      "metadata": {
        "id": "DtTnfSsCQNTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "UX3nnLPlu8RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8576e738-dffb-4d18-8380-050881246e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['noun.quantity', 'adj.all', 'verb.possession', 'verb.emotion', 'adj.pert', 'verb.change', 'noun.body', 'verb.contact', 'noun.person', 'verb.stative', 'noun.communication', 'noun.artifact', 'noun.substance', 'noun.cognition', 'verb.communication', 'verb.cognition', 'noun.state', 'verb.social', 'noun.time', 'verb.creation', 'noun.act', 'verb.consumption', 'noun.object', 'noun.event', 'verb.motion', 'verb.perception', 'noun.feeling', 'noun.group', 'noun.process', 'verb.body', 'noun.attribute', 'noun.Tops', 'noun.animal', 'noun.plant', 'noun.location', 'noun.relation', 'noun.shape', 'verb.competition', 'noun.food', 'verb.weather', 'noun.possession', 'adj.ppl', 'noun.phenomenon', 'noun.motive', 'adv.all']\n",
            "45\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(seen)\n",
        "print(seen)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAF9my4vfpYY"
      },
      "source": [
        "Initialize your model. Use the same Regression class for logistic regression as for linear regression - the difference will come from the objective (loss) function. The output now is not a single number but scores for each of the classes in the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "xn7HvScVvazT"
      },
      "outputs": [],
      "source": [
        "logreg_model = Regression(glovedim,num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yxodwdYfzTl"
      },
      "source": [
        "**Exercise**. Choose the loss function. This is a crucial choice: some of the loss functions in PyTorch (see https://pytorch.org/docs/stable/nn.html) already include a softmax or a sigmoid in their implementaion, which gives computational advantages. Be sure to read the documentation on your loss function to confirm you made a good choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "HVRdqxAvvIPC"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "loss4logreg = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H-JrZZVfzHF"
      },
      "source": [
        "**Exercise**.  Initialize the optimiser:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "Jw6Pt_BKvTFx"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "logregoptimiser = torch.optim.SGD(logreg_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSNhlheCk4xN"
      },
      "source": [
        "WordNet is quite big. For efficiency, use the following function for splitting your data into batches when processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "IbA_NKV1k7vX"
      },
      "outputs": [],
      "source": [
        "batch_size = 200\n",
        "def get_batches(src_iter, tgt_iter, batch_size=batch_size):\n",
        "    for batch in more_itertools.chunked(zip(src_iter, tgt_iter), batch_size):\n",
        "        x, y = zip(*batch)\n",
        "        x = torch.stack(x)\n",
        "        y = torch.stack(y)\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2bMjQiKy04C"
      },
      "source": [
        "**Exercise**. Train and test your logistic regression model, printing the train and test loss and accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "ZpbabReyy3Gg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "949559f0bbcb4527907dc68f033d4ea6",
            "5d96f117b5e443cb81ec49d878ef9eae",
            "393a2d66a83e4e6f959ee7729fa09b97",
            "a93fe49ac5d34e70bfa6eac8304cc0c7",
            "21c2c38b694543cba4ade2c949b35efa",
            "a00ae7abf48749b3b95165b2d6a7be71",
            "0ce4cc4069594a10b6916acd6cb7accc",
            "4876085e4e294fc8870efeb7ee1537c6",
            "a4e61d149f974a16a678cb8772534a14",
            "3d736ccf97a94f6a99e10bdc86f7738a",
            "b34af7dfef6c404c974fd250e3f6c399"
          ]
        },
        "outputId": "9587d759-be9a-43ae-8704-e20cd4be2182"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "949559f0bbcb4527907dc68f033d4ea6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.9819555282592773, Train accuracy: 0.4603285494720453\n",
            "Test loss: 1.9709422588348389, Test accuracy: 0.4618286330159871\n"
          ]
        }
      ],
      "source": [
        "def accuracy(predictions, scores):\n",
        "  score = 0\n",
        "  for i in range(0,len(predictions)):\n",
        "    if predictions[i] == scores[i]:\n",
        "      score +=1\n",
        "  return score / len(scores)\n",
        "\n",
        "epocchs = 40\n",
        "for epoch in trange(epochs, desc='Training Epochs'):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for x,scores in get_batches(wn_words_train,wn_supersenses_train):\n",
        "      logregoptimiser.zero_grad()\n",
        "      outputs = logreg_model(x)\n",
        "      loss = loss4logreg(outputs, scores)\n",
        "      loss.backward()\n",
        "      logregoptimiser.step()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  predictions = logreg_model(wn_words_train)\n",
        "  plist = torch.argmax(predictions, dim=1).tolist()\n",
        "\n",
        "  scores= wn_supersenses_train\n",
        "  loss = loss4logreg(predictions, scores)\n",
        "  slist = scores.tolist()\n",
        "\n",
        "\n",
        "  trainAcc = accuracy(plist,slist)\n",
        "\n",
        "  testX = wn_words_test\n",
        "  testScores = wn_supersenses_test\n",
        "  testPredictions = logreg_model(testX)\n",
        "  testLoss = loss4logreg(testPredictions, testScores)\n",
        "  plist = torch.argmax(testPredictions, dim=1).tolist()\n",
        "  slist = wn_supersenses_test.tolist()\n",
        "  testAccuracy = accuracy(plist,slist)\n",
        "\n",
        "\n",
        "  print(f\"Train loss: {loss}, Train accuracy: {trainAcc}\")\n",
        "  print(f\"Test loss: {testLoss}, Test accuracy: {testAccuracy}\")\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDWmbmFEh8em"
      },
      "source": [
        "**Exercise**. Define a mapping from indices to lexicographic file names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TQFoIsxHgExM"
      },
      "outputs": [],
      "source": [
        "#your code\n",
        "itolexname = seen"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the name of lexicographic file 2?"
      ],
      "metadata": {
        "id": "4VXxnXovdGUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "zriTsMNl-8PC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4d4ecea1-d064-46dd-c721-b4717abe0532"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'verb.possession'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "itolexname[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eJ39Ocgik1Z"
      },
      "source": [
        "**Exercise**. Which supersense (lexicographic file) does your classifier assign to the noun _house_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "p1JuvmYvgMyk"
      },
      "outputs": [],
      "source": [
        "def predicted_lexname(wd):\n",
        "  model.eval()\n",
        "  predicted_index = logreg_model(torch.from_numpy(np.array(glove[wd])))\n",
        "  predicted_index = torch.argmax(predicted_index, dim = 0)\n",
        "  return itolexname[predicted_index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which supersense (lexicographic file) does your classifier assign to the noun _house_?"
      ],
      "metadata": {
        "id": "0YCvViZbRYHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_lexname(\"house\")"
      ],
      "metadata": {
        "id": "TB1mGbcoRZ5h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "86e9adbe-e8ea-4e4b-cb31-6f0991769839"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'noun.artifact'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRijRCGLiTyb"
      },
      "source": [
        "Which supersense (lexicographic file) does your classifier assign to the noun _hog_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "lgePacYfgezw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e83a47ef-8a47-422d-9ce9-f2085e8637a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'noun.animal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "predicted_lexname(\"hog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL8uxCpyzah1"
      },
      "source": [
        "# 2.5. Hypernymy classification\n",
        "\n",
        "Now, download a lexical entailment (hypernymy) dataset called WBLESS. The dataset was developed by Weeds et al. with the goal of testing models on distinguishing hypernyms from other related word pairs.\n",
        "\n",
        "Weeds et al. (2014) Julie Weeds, Daoud Clarke, Jeremy Reffin, David Weir, and Bill Keller. 2014. Learning to distinguish hypernyms and co-hyponyms. In Proceedings of the 2014 International Conference on Computational Linguistics, pages 2249–2259, Dublin, Ireland.\n",
        "\n",
        "WBLESS (together with other relevant datasets) can be conveniently downloaded from the Facebook Research github page by Stephen Roller who worked on hypernymy learning:\n",
        "\n",
        "Stephen Roller, Douwe Kiela, and Maximilian Nickel. 2018. Hearst Patterns Revisited: Automatic Hypernym Detection from Large Text Corpora. ACL.\n",
        "\n",
        "Download the tab-separated dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "UC37FAiq0TN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a67952-192a-43bd-82e4-e48bcd6847f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-10 10:10:54--  https://github.com/facebookresearch/hypernymysuite/raw/main/data/wbless.tsv\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/facebookresearch/hypernymysuite/main/data/wbless.tsv [following]\n",
            "--2026-02-10 10:10:54--  https://raw.githubusercontent.com/facebookresearch/hypernymysuite/main/data/wbless.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51267 (50K) [text/plain]\n",
            "Saving to: ‘wbless.tsv’\n",
            "\n",
            "wbless.tsv          100%[===================>]  50.07K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2026-02-10 10:10:54 (4.15 MB/s) - ‘wbless.tsv’ saved [51267/51267]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/facebookresearch/hypernymysuite/raw/main/data/wbless.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqCX7YDt27Vs"
      },
      "source": [
        "Check how the data looks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "qfLFN1110Zuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0504e333-b971-4bd6-b6c5-356e86e20e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word1\tword2\tlabel\trelation\tfold\n",
            "frigate\tcraft\tTrue\thyper\tval\n",
            "trouble\tcarp\tFalse\tother\tval\n",
            "fox\tmouth\tFalse\tother\tval\n",
            "foot\trobin\tFalse\tother\tval\n",
            "vest\tgarment\tTrue\thyper\tval\n",
            "beetle\tinsect\tTrue\thyper\tval\n",
            "axe\tutensil\tTrue\thyper\tval\n",
            "chair\tscroll\tFalse\tother\tval\n",
            "end\tspear\tFalse\tother\tval\n"
          ]
        }
      ],
      "source": [
        "!head wbless.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8H2DTxmi45e"
      },
      "source": [
        "We used ```csv``` above to process a tab separated file. It can also be done using ```pandas```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "HcKADH0wT-dJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "dec2054f-001b-4aa3-9eec-e528e34393b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     word1    word2  label relation fold\n",
              "0  frigate    craft   True    hyper  val\n",
              "1  trouble     carp  False    other  val\n",
              "2      fox    mouth  False    other  val\n",
              "3     foot    robin  False    other  val\n",
              "4     vest  garment   True    hyper  val"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d58eae9f-7955-4ec1-a00e-0c8651751859\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word1</th>\n",
              "      <th>word2</th>\n",
              "      <th>label</th>\n",
              "      <th>relation</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frigate</td>\n",
              "      <td>craft</td>\n",
              "      <td>True</td>\n",
              "      <td>hyper</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trouble</td>\n",
              "      <td>carp</td>\n",
              "      <td>False</td>\n",
              "      <td>other</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fox</td>\n",
              "      <td>mouth</td>\n",
              "      <td>False</td>\n",
              "      <td>other</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>foot</td>\n",
              "      <td>robin</td>\n",
              "      <td>False</td>\n",
              "      <td>other</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vest</td>\n",
              "      <td>garment</td>\n",
              "      <td>True</td>\n",
              "      <td>hyper</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d58eae9f-7955-4ec1-a00e-0c8651751859')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d58eae9f-7955-4ec1-a00e-0c8651751859 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d58eae9f-7955-4ec1-a00e-0c8651751859');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "wbless_df",
              "summary": "{\n  \"name\": \"wbless_df\",\n  \"rows\": 1668,\n  \"fields\": [\n    {\n      \"column\": \"word1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 441,\n        \"samples\": [\n          \"cranberry\",\n          \"gill\",\n          \"vertebrate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"club\",\n          \"ambulance\",\n          \"runner-up\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"other\",\n          \"hyper\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"test\",\n          \"val\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "wbless_df = pd.read_csv('wbless.tsv', sep='\\t')\n",
        "wbless_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78WU2dWP3GvT"
      },
      "source": [
        "**Exercise**. Now create training and test data for relation classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "8kP1WKoj3HN2"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "wbless_words = []\n",
        "hypernymy = []\n",
        "for inrdex,row in wbless_df.iterrows():\n",
        "    word1=row[\"word1\"]\n",
        "    word2=row[\"word2\"]\n",
        "    if word1 in glove and word2 in glove:\n",
        "      wbless_words.append(word1)\n",
        "      wbless_words.append(word2)\n",
        "      if(row[\"label\"] == True):\n",
        "        hypernymy.append(1)\n",
        "      else:\n",
        "        hypernymy.append(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkUxGPQN2ODk"
      },
      "source": [
        "Split into training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5TADig-3VZ_"
      },
      "outputs": [],
      "source": [
        "wbless_words_train, wbless_words_test, hypernymy_train, hypernymy_test = train_test_split(wbless_words,hypernymy,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZNxIFOc3kN9"
      },
      "source": [
        "**Exercise**. Create, train and test a logistic regression model that predicts whether two words stand in the hypernymy relation given their GloVe vectors.\n",
        "\n",
        "Make sure your model predicts a single score used for the binary decision (hypernymy vs. non-hypernymy) rather than scores for multiple classes, and choose the loss function in pyTorch accordingly.\n",
        "\n",
        "Print the train and test loss and accuracy. Use the concatenation of the two words' vectors as input to the logistic regression classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "rkYFJcWH320c"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "second_class_model = Regression(2,1)\n",
        "loss_second = torch.nn.SoftMarginLoss()\n",
        "optimize_second =  torch.optim.SGD(logreg_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYuoCyuWm-NF"
      },
      "source": [
        "**Exercise**. What label does your model predict for the pair _dog,animal_? Your code below should produce a Boolean value, `True` for the positive class (hypernymy) and `False` for the negative class (not hypernymy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Kujrk1QjIJs"
      },
      "outputs": [],
      "source": [
        "def predicted_hypernymy(w1, w2):\n",
        "#your code here\n",
        "\n",
        "\n",
        "print(\"Predicted hypernymy, i.e. whether 'animal' is a hypernym of 'dog':\",predicted_hypernymy(\"dog\",\"animal\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gR6R_6LnL05"
      },
      "source": [
        "What label does your model predict for the pair _dog,cat_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n40gWmRjuf6"
      },
      "outputs": [],
      "source": [
        "print(\"Predicted hypernymy, i.e. whether 'cat' is a hypernym of 'dog':\",predicted_hypernymy(\"dog\",\"cat\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCKBTiCCnRRu"
      },
      "source": [
        "What label does your model predict for the pair _animal,dog_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_9JK2EnnT2d"
      },
      "outputs": [],
      "source": [
        "print(\"Predicted hypernymy, i.e. whether 'dog' is a hypernym of 'animal':\",predicted_hypernymy(\"animal\",\"dog\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.6 Using FrameNet\n",
        "\n"
      ],
      "metadata": {
        "id": "-xR2nXnH5HJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can explore FrameNet online:\n",
        "https://framenet.icsi.berkeley.edu/frameIndex\n",
        "\n",
        "Or read detailed documentation here:\n",
        "https://framenet2.icsi.berkeley.edu/docs/r1.7/book.pdf\n",
        "\n",
        "Now, load FrameNet via the NLTK package:"
      ],
      "metadata": {
        "id": "nENYVvXQiwMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('framenet_v17')\n",
        "from nltk.corpus import framenet as fn"
      ],
      "metadata": {
        "id": "zyuhOo7m8n72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9314a114-54e1-44f1-dbdf-04a7bb43363c"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package framenet_v17 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/framenet_v17.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fn.lus` allows to retrieve lexical units (LUs) recorded in FrameNet. A lexical unit approximately corresponds to a lemma in WordNet, i.e. a word taken in a specific sense. Without additional parameters, it returns a complete list:\n",
        "\n"
      ],
      "metadata": {
        "id": "K7PE47iCaR2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lus()"
      ],
      "metadata": {
        "id": "ijewRC_JaShn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be38f689-ea2a-4c94-c9c9-0438d4988837"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<lu ID=16601 name=(can't) help.v>, <lu ID=14632 name=(in/out of) line.n>, ...]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also retrieve lexical units by regular expression search. For example, the following returns the list of LUs that contain string _pres_ at the beginning of the LU name:"
      ],
      "metadata": {
        "id": "SC2XBdpyauNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lus('^pres')"
      ],
      "metadata": {
        "id": "uJCGq6a181-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab0dc89-0a66-4b2b-867e-3ee4d642a5a3"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<lu ID=7547 name=presage.n>, <lu ID=7546 name=presage.v>, ...]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Individual lexical units can be retrieved by ID, for example:"
      ],
      "metadata": {
        "id": "aKfBkMyPbbLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117)"
      ],
      "metadata": {
        "id": "LUpopayw9AFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f8425f-1eef-46de-b94e-fc4ac293eb45"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lexical unit (10117): press.v\n",
              "\n",
              "[definition]\n",
              "  COD: make strong efforts to persuade or force to do something.\n",
              "[frame] Attempt_suasion(87)\n",
              "\n",
              "[POS] V\n",
              "\n",
              "[status] Finished_Initial\n",
              "\n",
              "[lexemes] press/V\n",
              "\n",
              "[semTypes] 0 semantic types\n",
              "\n",
              "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu10117.xml\n",
              "\n",
              "[subCorpus] 12 subcorpora\n",
              "  01-T-Won-(1), 02-T-Wto-(1), 03-T-Winto-(1), 04-T-Wwith-(1),\n",
              "  05-T-Wfor-(1), 06-AVP-T-(1), 07-T-AVP-(1), 08-T-NP-PP-(1),\n",
              "  09-T-NP-(1), manually-added, other-matched-(1), other-\n",
              "  unmatched-(1)\n",
              "\n",
              "[exemplars] 20 sentences across all subcorpora"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terms that show up in square brackets are attributes, in this case of the lexical unit. They include usage examples:"
      ],
      "metadata": {
        "id": "9QHkZL7Xb2me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117).exemplars"
      ],
      "metadata": {
        "id": "tzDT4Cuob5Ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c38e65-48af-4e72-cf10-16048893ae70"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "exemplar sentences for press.v in Attempt_suasion:\n",
              "\n",
              "[0] The sponsors of the bill made clear their intention to press for a vote on it within the current legislative session .\n",
              "[1] Anne McIntosh , MEP for North East Essex , is pressing the Government to reverse its policy of controlled retreat , which allows the sea to gradually take its natural course .\n",
              "[2] Lewis pressed Adam to accompany him on those solicitous weekend visits but Adam nearly always said he was too busy or would be bored .\n",
              "[3] The committee also agreed to press for changes to the rule which limits the level of right-to-buy discounts in the case of newly built houses or those recently modernised .\n",
              "[4] It is no secret that Damascus has been using the PKK as a bargaining chip to press Turkey into complying with its demands for more water from the Euphrates , on which it heavily depends .\n",
              "[5] The tenant 's adviser should therefore press for an obligation on the landlord to notify the tenant of any application made by him to the President .\n",
              "[6] They press for much needed democratic reforms to enable the citizens to participate .\n",
              "[7] When I press him for more names he suddenly gets the deer-caught-in-the-headlights look , and , deciding he 's already revealed too much , replies , ` Ah , just people . \"\n",
              "[8] In these circumstances the Soviet Union has pressed more recently for a more limited regime for the Gulf involving restrictions on the naval presence of the Great Powers in the region .\n",
              "[9] Mr Gorbachev may refrain from saying it publicly on Saturday but he can be expected to press Mr Honecker all the more urgently in private .\n",
              "[10] The houses of Hohenstaufen ( Ghibellines ) and Welf ( Guelphs ) both pressed their claims to the royal crown but as already described , Frederick Barbarossa succeeded in his claim .\n",
              "[11] BRITISH Petroleum is to press Chancellor Norman Lamont for a reduction in North Sea taxes and is making additional cuts in capital spending to avoid the risks of further cash and dividend pressures .\n",
              "[12] We will press them to put into practice the principles of the Maastricht declaration .\n",
              "[13] Once in office Healey pressed his Nato colleagues to accept that no conflict was possible in Europe at any level between that of a local skirmish and all-out war .\n",
              "[14] Suppose she was pressing him to pay it back because she needed it for her vineyard . \"\n",
              "[15] I would n't press you for a decision , I promise you .\n",
              "[16] We will press for similar standards throughout the European Community and strengthen the work of consumer groups and advice centres so that the aspirations and standards are met .\n",
              "[17] Senior Tories pressed Michael Heseltine , the environment secretary , to discuss radical changes to the poll tax .\n",
              "[18] With membership of the Church of England steadily dwindling , strong-willed vicars are pressing equally strong-willed and often non-religious ringers to attend services .\n",
              "[19] QN : Did Sharon urge the US leader to keep pressing Iran to give up its nuclear program altogether ?\n"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and the frame that the lexical unit evokes, which in turn has its own attributes:"
      ],
      "metadata": {
        "id": "ef8vlLl_ckrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117).frame"
      ],
      "metadata": {
        "id": "GWKLSgeEbqi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d67f024-c7e0-4e31-e1b6-b55b1127b4ea"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "frame (87): Attempt_suasion\n",
              "\n",
              "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Attempt_suasion.xml\n",
              "\n",
              "[definition]\n",
              "  The  Speaker expresses through language his wish to get the\n",
              "  Addressee to act in some way that will help to bring about events\n",
              "  or states described in the Content. There is no implication that\n",
              "  the Addressee forms an intention to act, let alone acts.     'Mr\n",
              "  Smithers always encourages the employees to stay late and work\n",
              "  harder.'  'Dennis Rodman advises moderation in all things. INI'\n",
              "  The Content most prototypically refers to an action that the\n",
              "  Addressee will carry out themselves, but may (in the case of\n",
              "  valences with a non-finite Content clause) merely refer to a\n",
              "  situation that they have indirect influence over, as in the\n",
              "  following  'When I talked to her, I suggested that he be removed\n",
              "  from office . DNI '\n",
              "[semTypes] 0 semantic types\n",
              "\n",
              "[frameRelations] 8 frame relations\n",
              "  <Parent=Attempt -- Inheritance -> Child=Attempt_suasion>\n",
              "  <Parent=Attempt_suasion -- Using -> Child=Suasion>\n",
              "  <Parent=Communication -- Using -> Child=Attempt_suasion>\n",
              "  <Parent=Subjective_influence -- Using -> Child=Attempt_suasion>\n",
              "  <Source=Attempt_suasion -- ReFraming_Mapping -> Target=Causation>\n",
              "  <Source=Attempt_suasion -- ReFraming_Mapping -> Target=Manipulate_into_doing>\n",
              "  <Source=Attempt_suasion -- ReFraming_Mapping -> Target=Subjective_influence>\n",
              "  <Source=Request -- ReFraming_Mapping -> Target=Attempt_suasion>\n",
              "\n",
              "[lexUnit] 16 lexical units\n",
              "  admonish.v (1809), advise.v (1810), advocate.v (13475), beg.v\n",
              "  (1812), cajole.v (1813), enjoin.v (18519), exhort.v (1818),\n",
              "  lobby.v (13116), press.v (10117), pressure.n (11455), pressure.v\n",
              "  (1820), prevail.v (1821), recommend.v (16934), suggest.v (16340),\n",
              "  suggestion.n (18450), urge.v (1805)\n",
              "\n",
              "[FE] 20 frame elements\n",
              "            Core: Addressee (409), Content (408), Medium (427), Salient_entity (14440), Speaker (410), Topic (414)\n",
              "      Peripheral: Degree (1225), Manner (1222), Means (1224), Place (12626), Purpose (13346), Time (10234)\n",
              "  Extra-Thematic: Circumstances (10237), Depictive (1223), Explanation (10235), Frequency (10511), Group (10508), Period_of_iterations (10236), Re-encoding (10513), Role (15518)\n",
              "\n",
              "[FEcoreSets] 2 frame element core sets\n",
              "  Content, Topic\n",
              "  Speaker, Medium"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Find all LUs on FrameNet that share the frame with the noun *car*. Print these words along with their definitions."
      ],
      "metadata": {
        "id": "Cctg8so28msu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lu in fn.lus(name=\"car.n\")[0].frame.lexUnit.values():\n",
        "  print(f\"{lu.name}, {lu.definition}\")"
      ],
      "metadata": {
        "id": "-dOO4w5i5Lf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e9a00a-47ee-4231-ed7c-35a3f63e7388"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car.n, COD: a powered road vehicle designed to carry a small number of people\n",
            "bus.n, COD: a large motor vehicle carrying paying passengers on a fixed route\n",
            "truck.n, COD: a large road vehicle, used for carrying goods, materials, or troops. \n",
            "bike.n, COD: a bicycle or motorcycle.\n",
            "taxi.n, COD: motor vehicle licensed to transport passengers in return for payment of a fare.\n",
            "plane.n, COD: a powered flying vehicle with fixed wings and a weight greater than that of the air it displaces.\n",
            "ferry.n, COD: a boat or ship for conveying passengers and goods, especially as a regular service.\n",
            "boat.n, COD: a small vessel propelled by oars, sails, or an engine. \n",
            "bicycle.n, COD: a vehicle consisting of two wheels held in a frame one behind the other, propelled by pedals and steered with handlebars attached to the front wheel. \n",
            "ship.n, COD: a large seagoing boat. \n",
            "tram.n, COD: a passenger vehicle powered by electricity conveyed by overhead cables, and running on rails laid in a public road. \n",
            "automobile.n, COD:  a motor car. \n",
            "tricycle.n, COD: a vehicle similar to a bicycle, but having three wheels, two at the back and one at the front. or a three-wheeled motor vehicle for a disabled driver. \n",
            "airplane.n, COD: a powered flying vehicle with fixed wings and a weight greater than that of the air it displaces. \n",
            "scooter.n, COD: a light two-wheeled motorcycle. \n",
            "schooner.n, COD: a sailing ship with two or more masts, typically with the foremast smaller than the mainmast. \n",
            "train.n, COD: a series of railway carriages or wagons moved as a unit by a locomotive or by integral motors. \n",
            "carriage.n, COD: a four-wheeled passenger vehicle pulled by two or more horses. \n",
            "cab.n, COD: a taxi. \n",
            "coach.n, COD: a comfortably equipped single-decker bus used for longer journeys.\n",
            "vehicle.n, COD: a thing used for transporting people or goods on land, e.g. a car, truck, or cart.\n",
            "lorry.n, COD: a large, heavy motor vehicle for transporting goods or troops. \n",
            "submarine.n, COD: a streamlined warship designed to operate completely submerged in the sea for long periods.\n",
            "tank.n, COD: a heavy armoured fighting vehicle carrying guns and moving on a continuous articulated metal track.\n",
            "cart.n, COD: a light two-wheeled open vehicle for driving in, pulled by a single horse. \n",
            "toboggan.n, COD: a light, narrow vehicle, typically on runners, used for sliding downhill over snow or ice. \n",
            "pick-up.n, COD: a small van or truck with low sides. \n",
            "van.n, COD: a covered motor vehicle used for transporting goods or people\n",
            "limousine.n, COD: a large, luxurious car, typically with a partition behind the driver. \n",
            "convertible.n, COD: a convertible car. \n",
            "helicopter.n, COD: a type of aircraft deriving both lift and propulsion from one or two sets of horizontally revolving rotors and capable of moving vertically and horizontally. \n",
            "canoe.n, COD: a narrow keelless boat with pointed ends, propelled with a paddle. \n",
            "kayak.n, COD: a canoe of a type used originally by the Inuit, made of a light frame with a watertight covering having a small opening for the seat. \n",
            "buggy.n, COD: a small motor vehicle with an open top. \n",
            "liner.n, COD: a large passenger ship of a type formerly used on a regular line.\n",
            "sedan.n, COD: a motor car for four or more people.\n",
            "vessel.n, COD: a ship or large boat.  \n",
            "tank car.n, FN: a car of a freight train which is designed to hold liquids.\n",
            "warplane.n, FN: a plane used in war\n",
            "yacht.n, COD: a boat with sails and sometimes an engine, used for either racing or travelling on for pleasure:\n",
            "chopper.n, FN: helicopter.\n",
            "helo.n, FN: helicopter.\n",
            "bird.n, FN: an aircraft.\n",
            "minivan.n, FN: a large personal-use motor vehicle used to transport larger numbers of people\n",
            "ambulance.n, FN: a emergency vehicle with provisions for transporting and caring for patients.\n",
            "aircraft.n, FN: A vehicle designed to travel in air.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Define a function that takes a FrameNet frame as input and prints out the definitions of all core frame elements associated with the frame. For example, for the frame associated with the noun _car_ your function will print the definition of the only core frame element _Vehicle_:\n",
        "\n",
        "\n",
        "> Vehicle is the transportation device that the human beings use to travel.This FE is incorporated into each LU in this frame.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7EdFxMeWhdOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printcoreFE(frame):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    frame: a frame object from FrameNet\n",
        "  \"\"\"\n",
        "  coreElements = [fe for fe in frame.FE.values() if fe.coreType == \"Core\"]\n",
        "  for ce in coreElements:\n",
        "    print(f\"{ce.name}, {ce.definition}\")"
      ],
      "metadata": {
        "id": "cwp_SmRRflyv"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Test your function on the frame evoked by the verb _sing_:\n",
        "\n"
      ],
      "metadata": {
        "id": "fa_r8tEeiWtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sing = fn.lus(name=\"sing.v\")[0].frame\n",
        "\n",
        "printcoreFE(frame=sing)"
      ],
      "metadata": {
        "id": "hpCNSPF6gkpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ac893d-1e2d-454a-a5fd-6b6f060b469e"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker, Speaker is the sentient entity that produces a Message or communicates about a Topic. It is expressed as the External Argument of verbs:  'The boy mumbled an apology. '\n",
            "Addressee, Addressee is the person to whom the Speaker  is communicating.  When expressed, the Addressee occurs as a PP Complement:   'The taxi driver chattered away to me about gardening. '\n",
            "Message, Message is the content which is communicated by the Speaker. The Message may be a direct quote, a finite complement clause or an NP Object:  '\"I- It was an accident,\" Jo stammered.' ' Jo stammered that it was an accident.' ' Jo stammered an apology. '\n",
            "Topic, Topic is the subject matter of the communicated Message.  It is normally expressed as a PP Complement headed by about and, in this frame, is frequently preceded by a quantificational noun which is treated as referring to the Message:  'The actor chattered about the difficulties of being famous.' 'The person next to me muttered something about pride coming before a fall. '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSCcawbNg4_m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "978f8dc2bfe6441dbc856a5f8bc02730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c2c377df9e84279a56baef188639811",
              "IPY_MODEL_67a2a90a9c354b48a9dda2de483a9f58",
              "IPY_MODEL_95be26cc875240bf8554b8003d1d7732"
            ],
            "layout": "IPY_MODEL_2e06529c9028469d96846b8030ed7967"
          }
        },
        "0c2c377df9e84279a56baef188639811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3477d0091db743e2ae0b25fd22908ef1",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a4cba0ba7b4a48b27e5268a79e7ce3",
            "value": "Training Epochs: 100%"
          }
        },
        "67a2a90a9c354b48a9dda2de483a9f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0ad5beb9334a0dbe4a3d9ef9d94bdf",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b474206b7424c54ab4421beac6e92dd",
            "value": 20
          }
        },
        "95be26cc875240bf8554b8003d1d7732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d982ea804184cda925022f0c9500c6f",
            "placeholder": "​",
            "style": "IPY_MODEL_96058744d7574566bede7d6b098a29d3",
            "value": " 20/20 [00:00&lt;00:00,  5.97it/s]"
          }
        },
        "2e06529c9028469d96846b8030ed7967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3477d0091db743e2ae0b25fd22908ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a4cba0ba7b4a48b27e5268a79e7ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f0ad5beb9334a0dbe4a3d9ef9d94bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b474206b7424c54ab4421beac6e92dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d982ea804184cda925022f0c9500c6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96058744d7574566bede7d6b098a29d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "949559f0bbcb4527907dc68f033d4ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d96f117b5e443cb81ec49d878ef9eae",
              "IPY_MODEL_393a2d66a83e4e6f959ee7729fa09b97",
              "IPY_MODEL_a93fe49ac5d34e70bfa6eac8304cc0c7"
            ],
            "layout": "IPY_MODEL_21c2c38b694543cba4ade2c949b35efa"
          }
        },
        "5d96f117b5e443cb81ec49d878ef9eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a00ae7abf48749b3b95165b2d6a7be71",
            "placeholder": "​",
            "style": "IPY_MODEL_0ce4cc4069594a10b6916acd6cb7accc",
            "value": "Training Epochs: 100%"
          }
        },
        "393a2d66a83e4e6f959ee7729fa09b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4876085e4e294fc8870efeb7ee1537c6",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4e61d149f974a16a678cb8772534a14",
            "value": 20
          }
        },
        "a93fe49ac5d34e70bfa6eac8304cc0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d736ccf97a94f6a99e10bdc86f7738a",
            "placeholder": "​",
            "style": "IPY_MODEL_b34af7dfef6c404c974fd250e3f6c399",
            "value": " 20/20 [00:12&lt;00:00,  1.67it/s]"
          }
        },
        "21c2c38b694543cba4ade2c949b35efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00ae7abf48749b3b95165b2d6a7be71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce4cc4069594a10b6916acd6cb7accc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4876085e4e294fc8870efeb7ee1537c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e61d149f974a16a678cb8772534a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d736ccf97a94f6a99e10bdc86f7738a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34af7dfef6c404c974fd250e3f6c399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}