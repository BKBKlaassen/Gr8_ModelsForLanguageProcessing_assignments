{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BKBKlaassen/Gr8_ModelsForLanguageProcessing_assignments/blob/main/Group_8_M4LP_Assignment_2_(2026).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zydk5m0FpaKT"
      },
      "source": [
        "## Assignment 2\n",
        "\n",
        "This is the complete Assignment 2. You are asked to train and test linear and logistic regression models and access lexical resources."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Contributions</font>\n",
        "\n",
        "\n",
        "* group number: 8\n",
        "* Bjorn Klaassen, Noah de Jonge\n",
        "* Done together: , Bjorn Klaassen: , Noah de Jonge:"
      ],
      "metadata": {
        "id": "8rvH77dcj-2Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ledaEclUpvzT"
      },
      "source": [
        "To start the assignment, import prerequisite packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bRh6vltQpvTn"
      },
      "outputs": [],
      "source": [
        "import nltk,sklearn\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import collections, itertools\n",
        "import more_itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe word embeddings will be loaded through gensim package:"
      ],
      "metadata": {
        "id": "q1Gjwmay1urI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is all you need. **Do not import anything else at other points** except where suggested.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J45SbnKlSIbx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKO1jxm3pv93"
      },
      "source": [
        "# 2.1 Load GloVe word embedding model\n",
        "\n",
        "GloVe contains _static_ word embeddings. This means that the vector is assigned to word types and does not vary in different contexts or for different word senses. Pretrained GloVe word embedding models exist in different sizes. For the purpose of the exercise, we will use the smallest GloVe vectors with 50 dimensions. First, let's download the vectors and load the embedding model as `glove`. This may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RpbzSKOiuYge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb752ec-5248-403b-ae8a-0113697428f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "metadata": {
        "id": "z4GPth-uIwMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f20f4d0-fcf5-4e3a-ad1b-3316ebe72e5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another download workaround**. Sometimes StanfordNLP server is down and the embeddings don't load. In this case, you can obtain them from other sources. For example, download the embeddings from Kaggle (https://www.kaggle.com/datasets/rtatman/glove-global-vectors-for-word-representation?select=glove.6B.50d.txt), unzip the file and upoad it to the Colab working directory (left panel on Colab). Then uncomment and run:"
      ],
      "metadata": {
        "id": "QCFjiiY9FFiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from gensim.models import KeyedVectors\n",
        "#glove = KeyedVectors.load_word2vec_format('glove.6B.50d.txt', binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "-nvSK6__CQ1V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPoOZtlxqII4"
      },
      "source": [
        "The exercises below require understanding of gensim vector spaces. You can learn some basics from a tutorial on [word2vec](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html), which is an alternative to GloVe. For example, you will see in the tutorial that gensim word2vec has `wv.index_to_key` and `wv.key_to_index` attributes. By using a similar attribute of `glove`, we can count how many words the GloVe embeddings contain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4JMWM-iTqHNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db366ad3-f756-4feb-9ada-8f0b8eceeb50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(glove.key_to_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check if particular orthographic words have vectors in `glove`.\n",
        "\n",
        "**Exercise**. Check if strings 'asdfdfasd', \"catc\", \"cact\", and \"cat\" have a glove vector, and print the resuts as truth values."
      ],
      "metadata": {
        "id": "6iaJetpi504A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "stringList = ['asdfdfasd', \"catc\", \"cact\",\"cat\" ]\n",
        "for string in stringList:\n",
        "  try:\n",
        "    glove[string]\n",
        "    print(True)\n",
        "  except KeyError:\n",
        "    print(False)\n",
        "\n"
      ],
      "metadata": {
        "id": "jfmuq9kNyRhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b9d7e9-2095-41f6-f07e-9a9394ca5898"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkVR4dXbqOSY"
      },
      "source": [
        "**Exercise**. What is the vector of _cat_? Print it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0-EQf6-dqN_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09dc715b-417c-4104-b902-0d2d7cb9f081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.45281  -0.50108  -0.53714  -0.015697  0.22191   0.54602  -0.67301\n",
            " -0.6891    0.63493  -0.19726   0.33685   0.7735    0.90094   0.38488\n",
            "  0.38367   0.2657   -0.08057   0.61089  -1.2894   -0.22313  -0.61578\n",
            "  0.21697   0.35614   0.44499   0.60885  -1.1633   -1.1579    0.36118\n",
            "  0.10466  -0.78325   1.4352    0.18629  -0.26112   0.83275  -0.23123\n",
            "  0.32481   0.14485  -0.44552   0.33497  -0.95946  -0.097479  0.48138\n",
            " -0.43352   0.69455   0.91043  -0.28173   0.41637  -1.2609    0.71278\n",
            "  0.23782 ]\n"
          ]
        }
      ],
      "source": [
        "#your code here\n",
        "cat_vec = glove[\"cat\"]\n",
        "print(cat_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Which dimensions of vectors for \"cat\" and \"dog\" are similar, i.e. different by no more than 0.25? Print their indices. How many such dimensions are there? What is the proportion of similar dimensions out of all dimensions?\n",
        "\n"
      ],
      "metadata": {
        "id": "SznYrJv4KVOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n",
        "dog_vec = glove[\"dog\"]\n",
        "\n",
        "similar_dimensions = []\n",
        "\n",
        "for index in range(0,len(dog_vec)):\n",
        "  if(abs(dog_vec[index]-cat_vec[index]) <= 0.25):\n",
        "    similar_dimensions.append(index)\n",
        "\n",
        "print(\"Indices of similar dimensions:\",similar_dimensions)\n",
        "print(\"Number of similar dimensions:\", len(similar_dimensions))\n",
        "print(\"Proportion of similar dimensions:\",len(similar_dimensions), \"/\", len(dog_vec))\n"
      ],
      "metadata": {
        "id": "KMkVBIXpOfDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d9c7b2-3451-427e-a729-7856e3bc52d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of similar dimensions: [1, 2, 5, 11, 13, 14, 18, 20, 21, 24, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 48, 49]\n",
            "Number of similar dimensions: 29\n",
            "Proportion of similar dimensions: 29 / 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Compute the cosine of vectors for _cat_ and _dog_ using a gensim built-in function."
      ],
      "metadata": {
        "id": "Aqh_sjbD2i_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n",
        "print(glove.similarity(\"cat\",\"dog\"))\n"
      ],
      "metadata": {
        "id": "-yoE2TmL2N4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7eb3886-5904-4d26-bfda-3b8ccc55207e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9218005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byR4o0uZuYU0"
      },
      "source": [
        "# 2.2 Linear regression: Concreteness prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MudXBEHPqZQR"
      },
      "source": [
        "Obtain concreteness ratings from the paper\n",
        "\n",
        "Brysbaert, M., Warriner, A., & Kuperman, V. (2014). Concreteness ratings for 40 thousand generally known English word lemmas. BEHAVIOR RESEARCH METHODS, 46 (3), 904–911. https://doi.org/10.3758/s13428-013-0403-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cpty1jvvqZxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d48c62-148e-4a95-b2f1-d34cb201b581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-09 18:09:34--  https://raw.githubusercontent.com/ArtsEngine/concreteness/master/Concreteness_ratings_Brysbaert_et_al_BRM.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1646191 (1.6M) [text/plain]\n",
            "Saving to: ‘Concreteness_ratings_Brysbaert_et_al_BRM.txt’\n",
            "\n",
            "Concreteness_rating 100%[===================>]   1.57M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2026-02-09 18:09:35 (11.8 MB/s) - ‘Concreteness_ratings_Brysbaert_et_al_BRM.txt’ saved [1646191/1646191]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/ArtsEngine/concreteness/master/Concreteness_ratings_Brysbaert_et_al_BRM.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTWFbrn6q1gE"
      },
      "source": [
        "This is a tab-separated file with a header. Structured data like this can be conveniently read via DictReader class from csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koGwR3hfrNR_"
      },
      "source": [
        "Using DictReader, we create lists ```concreteness_words``` and ```concreteness_scores``` of words in the concreteness ratings file that have a GloVe vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YwSaCcHBrhjf"
      },
      "outputs": [],
      "source": [
        "concreteness_words=[]\n",
        "concreteness_scores=[]\n",
        "with open(\"Concreteness_ratings_Brysbaert_et_al_BRM.txt\",'r') as concfile:\n",
        "  read_tsv = csv.DictReader(concfile, delimiter=\"\\t\")\n",
        "  for row in read_tsv:\n",
        "    word=row[\"Word\"]\n",
        "    if word in glove:\n",
        "      concreteness_words.append(word)\n",
        "      concreteness_scores.append(float(row[\"Conc.M\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many words ended up in your concreteness dataset?"
      ],
      "metadata": {
        "id": "0MQ7uWgvQxL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(concreteness_words))"
      ],
      "metadata": {
        "id": "_Gmj9W9VQAKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e945d56-022b-4d6b-fa0c-253466086342"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDKmvggQrq9X"
      },
      "source": [
        "We can now create train and test partitions of concreteness data (conc_words_train, conc_words_test, conc_scores_train, conc_scores_test) with 10% test and 90% training split. Do not use random state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tCoOZ32trriI"
      },
      "outputs": [],
      "source": [
        "conc_words_train, conc_words_test, conc_scores_train, conc_scores_test = train_test_split(concreteness_words,concreteness_scores,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKo12DqNr57Z"
      },
      "source": [
        "Convert data to torch tensor format to use in a regression model (ignore UserWarning):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IExC7ts2r6WF"
      },
      "outputs": [],
      "source": [
        "conc_vectors_train = torch.from_numpy(np.array([glove[word] for word in conc_words_train]))\n",
        "conc_vectors_test = torch.from_numpy(np.array([glove[word] for word in conc_words_test]))\n",
        "conc_scores_train = torch.tensor(conc_scores_train, dtype=torch.float32)\n",
        "conc_scores_test = torch.tensor(conc_scores_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise** Explain in a couple of sentences what the second and third lines of code in the above cell does.\n",
        "\n",
        "The second line assigns a collection of arrays that we split previously for testing, which are converted to the appropriate data-structure for pyTorch, to the variable conc_vector_test.\n",
        "\n",
        "The third line converts the scores for the training data into a pyTorch tensor (vector), and assigns it to conc_scores_train."
      ],
      "metadata": {
        "id": "RbIFJmZ7Vy8G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA41kZdKsKgR"
      },
      "source": [
        "Now we can define linear regression model in pyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Z1QduXYcsOj3"
      },
      "outputs": [],
      "source": [
        "class Regression(torch.nn.Module):\n",
        "     def __init__(self, input_dim, output_dim):\n",
        "         super(Regression, self).__init__()\n",
        "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "     def forward(self, x):\n",
        "         outputs = self.linear(x)\n",
        "         return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Study pyTorch documentation at\n",
        "\n",
        "https://docs.pytorch.org/tutorials/index.html\n",
        "\n",
        "to understand the definition of the regression class. Explain each line of the class definition above. For example, line 3 can be explained as follows:\n",
        "\n",
        "Line 3 `super(Regression, self).__init__()` initializes a new Regression model as an instance of the parent class `torch.nn.Module`\n",
        "\n",
        "Now explain all other lines of the class code.\n",
        "\n",
        "Line 1 `class Regression(torch.nn.Module):` Defines the class name of the new model:\"Regression\" which inherits from `torch.nn.Module.`\n",
        "\n",
        "Line 2 `def __init__(self, input_dim, output_dim):` this method is used to initialize a new instance of the model, it defines the layers of the network, it takes in the size of the input dimension and the size of the output dimension.\n",
        "\n",
        "Line 4 `self.linear = torch.nn.Linear(input_dim, output_dim)` Applies an affine linear transformation to the incoming data using the size of each input sample, and the size  of each output sample, as defined by input_dim and output_dim, repectively.\n",
        "\n",
        "Line 5 `def forward(self, x):` this method is specifies how data will pass through the network, it can be used to implement operations on the input data.\n",
        "\n",
        "Line 6 `outputs = self.linear(x)` applies the linear transformation through the network as defined in Line 4 and stores the result in output.\n",
        "\n",
        "Line 7 `return outputs` returns the result of the linear transformation that was stored in outputs."
      ],
      "metadata": {
        "id": "a2Hx3FTn7TWc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGGf2CJksYPp"
      },
      "source": [
        "A specific linear regression model can have the input dimensionality of our word embeddings and 1-dimensional input (the concretenss score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glovedim = 50"
      ],
      "metadata": {
        "id": "-A5qxOl3K15t"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YfQIuGBqsXoG"
      },
      "outputs": [],
      "source": [
        "model = Regression(glovedim,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQcK2QCqsy4P"
      },
      "source": [
        "To train the model, we need a loss function and an optimiser, including the learning rate parameter. We choose Mean Square Error loss (suitable for learning linear regression) and Stochastic Gradient Descent method with the learning rate of 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LJHqQcuaMcNL"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KIuhn2FeNCph"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How PyTorch learns from data**\n",
        "\n",
        "Training a neural network means adjusting its parameters (weights and biases) so that its predictions get closer to the true values. PyTorch does this in four steps, repeated each epoch:\n",
        "\n",
        "- **Forward pass**: Input data flows through the model to produce predictions. Behind the scenes, PyTorch builds a computation graph — a record of every operation performed on the data.\n",
        "- **Loss calculation**: We measure how wrong the predictions are using a loss function (here, mean squared error).\n",
        "- **Backward pass** (`loss.backward()`): PyTorch walks backward through the computation graph, calculating gradients — these tell us how much each parameter contributed to the error, and in which direction it should change.\n",
        "- **Parameter update** (`optimizer.step()`): The optimizer adjusts each parameter by a small amount in the direction that reduces the loss.\n",
        "\n",
        "We call `zero_grad()` at the start because PyTorch accumulates gradients by default — without clearing them, gradients from previous epochs would mix with the current ones.\n",
        "\n",
        "A **computation graph** represents how outputs are computed from inputs, step by step. For training purposes, the inputs are model parameters (`linear.weight` and `linear.bias`) and the output is the loss value. A computation graph can be visualized in a diagram like:\n",
        "\n",
        "```\n",
        "  ┌───────────────────────┐\n",
        "  │   linear.weight       │\n",
        "  │   linear.bias         │\n",
        "  └───────────────────────┘\n",
        "              │\n",
        "              ▼\n",
        "           (Addmm)\n",
        "              │\n",
        "              ▼\n",
        "          (MseLoss)\n",
        "              │\n",
        "              ▼\n",
        "            loss\n",
        "            \n"
      ],
      "metadata": {
        "id": "O85a759PJxIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The computation graph (simplified for expository purposes) shows what PyTorch tracks: learnable parameters of the linear layer (weights and bias) udergo matrix multiplication with data and bias addition, then feed into the loss function.\n",
        "\n",
        "Why does the computation graph matter? To train the model, we need to know: \"If I nudge a weight slightly, how much does the loss change?\" When we call `loss.backward()`, PyTorch traverses this graph in reverse, from loss back to the parameters, computing gradients along the way. These gradients tell the optimizer how to adjust each parameter to reduce the loss."
      ],
      "metadata": {
        "id": "SVCOLO13NLO6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjjMEoVvtSc0"
      },
      "source": [
        "We can now train our linear regression model using gradient descent.\n",
        "\n",
        "**Exercise**. Every 5 training steps, evaluate the model, printing out loss and accuracy for the training and test sets. Calculate the accuracy as the percentage of examples where the predicted score of the model differs from the correct score by less than 1. The training may take a minute or so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uDQGZSxWsyPH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270,
          "referenced_widgets": [
            "8df46d9eebb447a2a769f1663513f642",
            "10c6d07969ec41818c37def420874ec8",
            "b199f43c32c348e89d52d4d69169c538",
            "dfb7c305b0544158b7c3d4736d0efa4b",
            "f638dae70ccb4ca188c24f01e6aafe39",
            "189ea4728ad74064be53716062bdbf63",
            "16b43ccf9b194bc3a1258a8b60228596",
            "4fc857d083af42dfa55f6ccd71dbf42c",
            "6338b38e7b75445bae9ff663ad3b31fa",
            "7149c822f87e41edb3d9da831fffdb84",
            "27eceb26f78143b1a5ec7a3b39a02603"
          ]
        },
        "outputId": "1949a7eb-6dc8-4f4f-9117-bb44d31b37a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training Epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8df46d9eebb447a2a769f1663513f642"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:\n",
            "Train loss: 0.5207660794258118, Train accuracy: 0.8344461917877197\n",
            "Test loss: 0.5139835476875305, Test accuracy: 0.8377609252929688\n",
            "Epoch 10:\n",
            "Train loss: 0.5031298995018005, Train accuracy: 0.8419314026832581\n",
            "Test loss: 0.4965219497680664, Test accuracy: 0.84566730260849\n",
            "Epoch 15:\n",
            "Train loss: 0.48985055088996887, Train accuracy: 0.8469215631484985\n",
            "Test loss: 0.4833499789237976, Test accuracy: 0.8510436415672302\n",
            "Epoch 20:\n",
            "Train loss: 0.4798164665699005, Train accuracy: 0.8516305685043335\n",
            "Test loss: 0.4733787775039673, Test accuracy: 0.8551549911499023\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "losses_test = []\n",
        "Iterations = []\n",
        "epochs=20\n",
        "tolerance = 1\n",
        "#after defining parameters, we train the model several times on the same data; each iteration is an epoch:\n",
        "for epoch in trange(epochs, desc='Training Epochs'):\n",
        "    x = conc_vectors_train\n",
        "    scores = conc_scores_train\n",
        "    #clear gradients from previous epoch (PyTorch accumulates them by default)\n",
        "    optimizer.zero_grad()\n",
        "    #here we pass the word vectors from the training set, obtaining regression model's predicted outputs:\n",
        "    outputs = model(x)\n",
        "    #compute the loss: how far are predictions from true scores?\n",
        "    loss = criterion(torch.squeeze(outputs), scores)\n",
        "    #compute gradients: how should each parameter change to reduce the loss?\n",
        "    loss.backward()\n",
        "    #update model parameters using the computed gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    #Now, every 5 epochs we can evaluate how the model performs on the data\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        #we don't compute gradients as the model is only evaluated and not updated\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            predictions = torch.squeeze(model(x))\n",
        "            loss = criterion(predictions, scores)\n",
        "            accuracy = (torch.abs(predictions - scores) <= tolerance).float().mean().item()\n",
        "            testX = conc_vectors_test\n",
        "            testScores = conc_scores_test\n",
        "            testPredictions = torch.squeeze(model(testX))\n",
        "            testLoss = criterion(testPredictions, testScores)\n",
        "            testAccuracy = (torch.abs(testPredictions - testScores) <= tolerance).float().mean().item()\n",
        "            print(f\"Epoch {epoch + 1}:\")\n",
        "            print(f\"Train loss: {loss}, Train accuracy: {accuracy}\")\n",
        "            print(f\"Test loss: {testLoss}, Test accuracy: {testAccuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The real computation graph used by pyTorch here is a little more complex than the schematic illustration we gave above; if you want to visualize it (using the familiar `graphviz` as the underlying engine), uncomment and run:"
      ],
      "metadata": {
        "id": "s2amIG-nNIyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torchviz\n",
        "#from torchviz import make_dot\n",
        "#make_dot(loss, params=dict(model.named_parameters()), show_attrs=False, show_saved=False)"
      ],
      "metadata": {
        "id": "ePPifiwLI5yM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <details>\n",
        "<summary><b>Click to see detailed explanation</b></summary>\n",
        "\n",
        "**Understanding the computation graph**\n",
        "\n",
        "The `torchviz` diagram shows the following nodes:\n",
        "\n",
        "| Node | What it is |\n",
        "|------|------------|\n",
        "| `linear.weight (1, 50)` | The learnable weight matrix of our linear layer: 50 input dimensions mapped to 1 output |\n",
        "| `linear.bias (1)` | The learnable bias term of our linear layer: a single value added to the output |\n",
        "| `AccumulateGrad` | A marker indicating \"this is a leaf node where gradients will be accumulated\" — appears next to each learnable parameter |\n",
        "| `TBackward0` | The backward operation for transpose (`T`): PyTorch transposes the weight matrix during the linear calculation |\n",
        "| `AddmmBackward0` | The backward operation for `addmm` (add + matrix multiply). This computes `bias + input @ weight.T`, which is what `nn.Linear` does internally |\n",
        "| `SqueezeBackward0` | The backward operation for `squeeze()`: shape adjustment from `(n, 1)` to `(n,)` |\n",
        "| `MseLossBackward0` | The backward operation for mean squared error loss |\n",
        "\n",
        "The \"Backward\" suffix indicates these are the *reverse* operations that PyTorch will use during backpropagation. The graph is built during the forward pass, but it stores the operations needed to compute gradients in reverse.\n",
        "\n",
        "Reading from bottom to top, the forward pass was:\n",
        "1. Take `linear.weight` and transpose it (`TBackward0`)\n",
        "2. Multiply input by transposed weights and add bias (`AddmmBackward0`)\n",
        "3. Squeeze the output shape (`SqueezeBackward0`)\n",
        "4. Compute MSE loss against target scores (`MseLossBackward0`)\n",
        "\n",
        "When we call `loss.backward()`, PyTorch traverses from top to bottom, computing gradients at each step until it reaches the `AccumulateGrad` nodes, where gradients are stored in `linear.weight.grad` and `linear.bias.grad`.\n",
        "</details>"
      ],
      "metadata": {
        "id": "y4x3sWCgOU1w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SJ3qAwKfDov"
      },
      "source": [
        "**Exercise**. What are the predicted concreteness score of the nouns _logarithm_ and _mouse_? Print them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "z76FnkTpAeO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff083341-d90f-41b9-cb58-f9948c454f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the scale from 1 to 5, our trained regression model predicts the concreteness scoere of 'logarithm' to be 3.0\n"
          ]
        }
      ],
      "source": [
        "def predicted_concreteness(wd):\n",
        "  model.eval()\n",
        "  predicted_score =  model(torch.from_numpy(np.array(glove[wd])))\n",
        "  return round(float(predicted_score[0]), 0)\n",
        "\n",
        "print(\"On the scale from 1 to 5, our trained regression model predicts the concreteness scoere of 'logarithm' to be\",predicted_concreteness(\"logarithm\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wu2jvBh5fAmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c4fbb9-07e5-4894-ff57-28ec7715ba8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the scale from 1 to 5, our trained regression model predicts the concreteness scoere of 'mouse' to be 5.0\n"
          ]
        }
      ],
      "source": [
        "print(\"On the scale from 1 to 5, our trained regression model predicts the concreteness scoere of 'mouse' to be\",predicted_concreteness(\"mouse\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6CTQkPAviBj"
      },
      "source": [
        "# 2.3. Create a dataset of WordNet supersenses for words that have GloVe vectors.\n",
        "\n",
        "First, download the WordNet database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0_TbA4Pfv9v5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301859b8-fc39-44dc-8874-758faf1c6aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can read documentation on object types in WordNet, for example by invoking the types:"
      ],
      "metadata": {
        "id": "gPVFTv6lngfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.reader.wordnet.Lemma"
      ],
      "metadata": {
        "id": "uLnPl63pnK-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "90c93dab-9435-44d9-8ae1-d39760afd250"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.corpus.reader.wordnet.Lemma"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.corpus.reader.wordnet.Lemma</b><br/>def __init__(wordnet_corpus_reader, synset, name, lexname_index, lex_id, syntactic_marker)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py</a>The lexical entry for a single morphological form of a\n",
              "sense-disambiguated word.\n",
              "\n",
              "Create a Lemma from a &quot;&lt;word&gt;.&lt;pos&gt;.&lt;number&gt;.&lt;lemma&gt;&quot; string where:\n",
              "&lt;word&gt; is the morphological stem identifying the synset\n",
              "&lt;pos&gt; is one of the module attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
              "&lt;number&gt; is the sense number, counting from 0.\n",
              "&lt;lemma&gt; is the morphological form of interest\n",
              "\n",
              "Note that &lt;word&gt; and &lt;lemma&gt; can be different, e.g. the Synset\n",
              "&#x27;salt.n.03&#x27; has the Lemmas &#x27;salt.n.03.salt&#x27;, &#x27;salt.n.03.saltiness&#x27; and\n",
              "&#x27;salt.n.03.salinity&#x27;.\n",
              "\n",
              "Lemma attributes, accessible via methods with the same name:\n",
              "\n",
              "- name: The canonical name of this lemma.\n",
              "- synset: The synset that this lemma belongs to.\n",
              "- syntactic_marker: For adjectives, the WordNet string identifying the\n",
              "  syntactic position relative modified noun. See:\n",
              "  https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "  For all other parts of speech, this attribute is None.\n",
              "- count: The frequency of this lemma in wordnet.\n",
              "\n",
              "Lemma methods:\n",
              "\n",
              "Lemmas have the following methods for retrieving related Lemmas. They\n",
              "correspond to the names for the pointer symbols defined here:\n",
              "https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "These methods all return lists of Lemmas:\n",
              "\n",
              "- antonyms\n",
              "- hypernyms, instance_hypernyms\n",
              "- hyponyms, instance_hyponyms\n",
              "- member_holonyms, substance_holonyms, part_holonyms\n",
              "- member_meronyms, substance_meronyms, part_meronyms\n",
              "- topic_domains, region_domains, usage_domains\n",
              "- attributes\n",
              "- derivationally_related_forms\n",
              "- entailments\n",
              "- causes\n",
              "- also_sees\n",
              "- verb_groups\n",
              "- similar_tos\n",
              "- pertainyms</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 219);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.reader.wordnet.Synset"
      ],
      "metadata": {
        "id": "e5PBoC8invpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d14c4168-14f3-49da-b2a6-9873977998e1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.corpus.reader.wordnet.Synset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.corpus.reader.wordnet.Synset</b><br/>def __init__(wordnet_corpus_reader)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py</a>Create a Synset from a &quot;&lt;lemma&gt;.&lt;pos&gt;.&lt;number&gt;&quot; string where:\n",
              "&lt;lemma&gt; is the word&#x27;s morphological stem\n",
              "&lt;pos&gt; is one of the module attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
              "&lt;number&gt; is the sense number, counting from 0.\n",
              "\n",
              "Synset attributes, accessible via methods with the same name:\n",
              "\n",
              "- name: The canonical name of this synset, formed using the first lemma\n",
              "  of this synset. Note that this may be different from the name\n",
              "  passed to the constructor if that string used a different lemma to\n",
              "  identify the synset.\n",
              "- pos: The synset&#x27;s part of speech, matching one of the module level\n",
              "  attributes ADJ, ADJ_SAT, ADV, NOUN or VERB.\n",
              "- lemmas: A list of the Lemma objects for this synset.\n",
              "- definition: The definition for this synset.\n",
              "- examples: A list of example strings for this synset.\n",
              "- offset: The offset in the WordNet dict file of this synset.\n",
              "- lexname: The name of the lexicographer file containing this synset.\n",
              "\n",
              "Synset methods:\n",
              "\n",
              "Synsets have the following methods for retrieving related Synsets.\n",
              "They correspond to the names for the pointer symbols defined here:\n",
              "https://wordnet.princeton.edu/documentation/wninput5wn\n",
              "These methods all return lists of Synsets.\n",
              "\n",
              "- hypernyms, instance_hypernyms\n",
              "- hyponyms, instance_hyponyms\n",
              "- member_holonyms, substance_holonyms, part_holonyms\n",
              "- member_meronyms, substance_meronyms, part_meronyms\n",
              "- attributes\n",
              "- entailments\n",
              "- causes\n",
              "- also_sees\n",
              "- verb_groups\n",
              "- similar_tos\n",
              "\n",
              "Additionally, Synsets support the following methods specific to the\n",
              "hypernym relation:\n",
              "\n",
              "- root_hypernyms\n",
              "- common_hypernyms\n",
              "- lowest_common_hypernyms\n",
              "\n",
              "Note that Synsets do not support the following relations because\n",
              "these are defined by WordNet as lexical relations:\n",
              "\n",
              "- antonyms\n",
              "- derivationally_related_forms\n",
              "- pertainyms</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 351);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Now, retrieve the first lemma corresponding to the adjective _dry_ as `d`:"
      ],
      "metadata": {
        "id": "_nCIbS2Zn7WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d= wn.lemma(\"dry.a.01.dry\")"
      ],
      "metadata": {
        "id": "FzpyC3J9mYXp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. What lemmas belong to the same SynSet? Retrieve the list."
      ],
      "metadata": {
        "id": "dhp5dHaeodHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d.synset().lemmas()"
      ],
      "metadata": {
        "id": "V29C-0zinUI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5478f7a9-cf64-409a-c9a9-9040089654b0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('dry.a.01.dry')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Define function `ant_freq` that returns the frequency of (the first) antonym of a lemma.\n"
      ],
      "metadata": {
        "id": "0_tAe2v8ojJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ant_freq(x):\n",
        "  return x.antonyms()[0].count()"
      ],
      "metadata": {
        "id": "wrtQvLOgmzd5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply `ant_freq` to `d`. This will output the frequency of _wet_."
      ],
      "metadata": {
        "id": "W63hTqccovBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ant_freq(d)"
      ],
      "metadata": {
        "id": "xbWZj8cqm3wR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a566f73-2713-4a6a-d3b9-c9d2bcf3209f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9UHFcCUwO_4"
      },
      "source": [
        "**Exercise**. Now, create a dataset that includes for each word in WordNet that has a GloVe vector the lexicographic file (supersense) of its first synset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "C43EVE68ytWG"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "\n",
        "wn_words = [w for w in wn.all_lemma_names() if w in glove]\n",
        "wn_supersenses = []\n",
        "seen = []\n",
        "for w in wn_words:\n",
        "  super = wn.synsets(w)[0].lexname()\n",
        "  if super in seen:\n",
        "    wn_supersenses.append(seen.index(super))\n",
        "  else:\n",
        "    wn_supersenses.append(len(seen))\n",
        "    seen.append(super)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHXhjXvjyt18"
      },
      "source": [
        "Split the dataset into train and test partitions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1lrFM_48yW83"
      },
      "outputs": [],
      "source": [
        "wn_words_train, wn_words_test, wn_supersenses_train, wn_supersenses_test = train_test_split(wn_words,wn_supersenses,test_size=0.1)\n",
        "\n",
        "wn_words_train = torch.from_numpy(np.array([glove[word] for word in wn_words_train]))\n",
        "wn_words_test = torch.from_numpy(np.array([glove[word] for word in wn_words_test]))\n",
        "wn_supersenses_train = torch.tensor(wn_supersenses_train, dtype=torch.long)\n",
        "wn_supersenses_test = torch.tensor(wn_supersenses_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0tWUqkugfe"
      },
      "source": [
        "# 2.4. Logistic regression: word class prediction.\n",
        "\n",
        "Now we can address a classification task. Define a (multinomial) regression model using softmax, choose a loss function and an optimizer for it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. We will need to set the number of classes for classification. Estimate `num_classes`prior to initializing the model. Use `wn_supersenses`."
      ],
      "metadata": {
        "id": "DtTnfSsCQNTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "UX3nnLPlu8RZ"
      },
      "outputs": [],
      "source": [
        "num_classes = len(seen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAF9my4vfpYY"
      },
      "source": [
        "Initialize your model. Use the same Regression class for logistic regression as for linear regression - the difference will come from the objective (loss) function. The output now is not a single number but scores for each of the classes in the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "xn7HvScVvazT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "e479b895-365c-479c-f3aa-b9c20d4c741b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'str' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2300253650.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogreg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglovedim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3711495343.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, output_dim)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m      \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ],
      "source": [
        "logreg_model = Regression(glovedim,num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yxodwdYfzTl"
      },
      "source": [
        "**Exercise**. Choose the loss function. This is a crucial choice: some of the loss functions in PyTorch (see https://pytorch.org/docs/stable/nn.html) already include a softmax or a sigmoid in their implementaion, which gives computational advantages. Be sure to read the documentation on your loss function to confirm you made a good choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVRdqxAvvIPC"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "loss4logreg ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H-JrZZVfzHF"
      },
      "source": [
        "**Exercise**.  Initialize the optimiser:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jw6Pt_BKvTFx"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "logregoptimiser ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSNhlheCk4xN"
      },
      "source": [
        "WordNet is quite big. For efficiency, use the following function for splitting your data into batches when processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbA_NKV1k7vX"
      },
      "outputs": [],
      "source": [
        "batch_size = 200\n",
        "def get_batches(src_iter, tgt_iter, batch_size=batch_size):\n",
        "    for batch in more_itertools.chunked(zip(src_iter, tgt_iter), batch_size):\n",
        "        x, y = zip(*batch)\n",
        "        x = torch.stack(x)\n",
        "        y = torch.stack(y)\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2bMjQiKy04C"
      },
      "source": [
        "**Exercise**. Train and test your logistic regression model, printing the train and test loss and accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpbabReyy3Gg"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDWmbmFEh8em"
      },
      "source": [
        "**Exercise**. Define a mapping from indices to lexicographic file names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQFoIsxHgExM"
      },
      "outputs": [],
      "source": [
        "#your code\n",
        "itolexname ="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the name of lexicographic file 2?"
      ],
      "metadata": {
        "id": "4VXxnXovdGUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zriTsMNl-8PC"
      },
      "outputs": [],
      "source": [
        "itolexname[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eJ39Ocgik1Z"
      },
      "source": [
        "**Exercise**. Which supersense (lexicographic file) does your classifier assign to the noun _house_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1JuvmYvgMyk"
      },
      "outputs": [],
      "source": [
        "def predicted_lexname(wd):"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which supersense (lexicographic file) does your classifier assign to the noun _house_?"
      ],
      "metadata": {
        "id": "0YCvViZbRYHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_lexname(\"house\")"
      ],
      "metadata": {
        "id": "TB1mGbcoRZ5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRijRCGLiTyb"
      },
      "source": [
        "Which supersense (lexicographic file) does your classifier assign to the noun _hog_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgePacYfgezw"
      },
      "outputs": [],
      "source": [
        "predicted_lexname(\"hog\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL8uxCpyzah1"
      },
      "source": [
        "# 2.5. Hypernymy classification\n",
        "\n",
        "Now, download a lexical entailment (hypernymy) dataset called WBLESS. The dataset was developed by Weeds et al. with the goal of testing models on distinguishing hypernyms from other related word pairs.\n",
        "\n",
        "Weeds et al. (2014) Julie Weeds, Daoud Clarke, Jeremy Reffin, David Weir, and Bill Keller. 2014. Learning to distinguish hypernyms and co-hyponyms. In Proceedings of the 2014 International Conference on Computational Linguistics, pages 2249–2259, Dublin, Ireland.\n",
        "\n",
        "WBLESS (together with other relevant datasets) can be conveniently downloaded from the Facebook Research github page by Stephen Roller who worked on hypernymy learning:\n",
        "\n",
        "Stephen Roller, Douwe Kiela, and Maximilian Nickel. 2018. Hearst Patterns Revisited: Automatic Hypernym Detection from Large Text Corpora. ACL.\n",
        "\n",
        "Download the tab-separated dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC37FAiq0TN3"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/facebookresearch/hypernymysuite/raw/main/data/wbless.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqCX7YDt27Vs"
      },
      "source": [
        "Check how the data looks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfLFN1110Zuc"
      },
      "outputs": [],
      "source": [
        "!head wbless.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8H2DTxmi45e"
      },
      "source": [
        "We used ```csv``` above to process a tab separated file. It can also be done using ```pandas```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcKADH0wT-dJ"
      },
      "outputs": [],
      "source": [
        "wbless_df = pd.read_csv('wbless.tsv', sep='\\t')\n",
        "wbless_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78WU2dWP3GvT"
      },
      "source": [
        "**Exercise**. Now create training and test data for relation classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kP1WKoj3HN2"
      },
      "outputs": [],
      "source": [
        "#your code here\n",
        "wbless_words =\n",
        "hypernymy ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkUxGPQN2ODk"
      },
      "source": [
        "Split into training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5TADig-3VZ_"
      },
      "outputs": [],
      "source": [
        "wbless_words_train, wbless_words_test, hypernymy_train, hypernymy_test = train_test_split(wbless_words,hypernymy,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZNxIFOc3kN9"
      },
      "source": [
        "**Exercise**. Create, train and test a logistic regression model that predicts whether two words stand in the hypernymy relation given their GloVe vectors.\n",
        "\n",
        "Make sure your model predicts a single score used for the binary decision (hypernymy vs. non-hypernymy) rather than scores for multiple classes, and choose the loss function in pyTorch accordingly.\n",
        "\n",
        "Print the train and test loss and accuracy. Use the concatenation of the two words' vectors as input to the logistic regression classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkYFJcWH320c"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYuoCyuWm-NF"
      },
      "source": [
        "**Exercise**. What label does your model predict for the pair _dog,animal_? Your code below should produce a Boolean value, `True` for the positive class (hypernymy) and `False` for the negative class (not hypernymy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Kujrk1QjIJs"
      },
      "outputs": [],
      "source": [
        "def predicted_hypernymy(w1, w2):\n",
        "#your code here\n",
        "\n",
        "\n",
        "print(\"Predicted hypernymy, i.e. whether 'animal' is a hypernym of 'dog':\",predicted_hypernymy(\"dog\",\"animal\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gR6R_6LnL05"
      },
      "source": [
        "What label does your model predict for the pair _dog,cat_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n40gWmRjuf6"
      },
      "outputs": [],
      "source": [
        "print(\"Predicted hypernymy, i.e. whether 'cat' is a hypernym of 'dog':\",predicted_hypernymy(\"dog\",\"cat\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCKBTiCCnRRu"
      },
      "source": [
        "What label does your model predict for the pair _animal,dog_?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_9JK2EnnT2d"
      },
      "outputs": [],
      "source": [
        "print(\"Predicted hypernymy, i.e. whether 'dog' is a hypernym of 'animal':\",predicted_hypernymy(\"animal\",\"dog\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.6 Using FrameNet\n",
        "\n"
      ],
      "metadata": {
        "id": "-xR2nXnH5HJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can explore FrameNet online:\n",
        "https://framenet.icsi.berkeley.edu/frameIndex\n",
        "\n",
        "Or read detailed documentation here:\n",
        "https://framenet2.icsi.berkeley.edu/docs/r1.7/book.pdf\n",
        "\n",
        "Now, load FrameNet via the NLTK package:"
      ],
      "metadata": {
        "id": "nENYVvXQiwMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('framenet_v17')\n",
        "from nltk.corpus import framenet as fn"
      ],
      "metadata": {
        "id": "zyuhOo7m8n72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fn.lus` allows to retrieve lexical units (LUs) recorded in FrameNet. A lexical unit approximately corresponds to a lemma in WordNet, i.e. a word taken in a specific sense. Without additional parameters, it returns a complete list:\n",
        "\n"
      ],
      "metadata": {
        "id": "K7PE47iCaR2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lus()"
      ],
      "metadata": {
        "id": "ijewRC_JaShn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also retrieve lexical units by regular expression search. For example, the following returns the list of LUs that contain string _pres_ at the beginning of the LU name:"
      ],
      "metadata": {
        "id": "SC2XBdpyauNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lus('^pres')"
      ],
      "metadata": {
        "id": "uJCGq6a181-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Individual lexical units can be retrieved by ID, for example:"
      ],
      "metadata": {
        "id": "aKfBkMyPbbLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117)"
      ],
      "metadata": {
        "id": "LUpopayw9AFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terms that show up in square brackets are attributes, in this case of the lexical unit. They include usage examples:"
      ],
      "metadata": {
        "id": "9QHkZL7Xb2me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117).exemplars"
      ],
      "metadata": {
        "id": "tzDT4Cuob5Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and the frame that the lexical unit evokes, which in turn has its own attributes:"
      ],
      "metadata": {
        "id": "ef8vlLl_ckrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn.lu(10117).frame"
      ],
      "metadata": {
        "id": "GWKLSgeEbqi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Find all LUs on FrameNet that share the frame with the noun *car*. Print these words along with their definitions."
      ],
      "metadata": {
        "id": "Cctg8so28msu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here"
      ],
      "metadata": {
        "id": "-dOO4w5i5Lf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Define a function that takes a FrameNet frame as input and prints out the definitions of all core frame elements associated with the frame. For example, for the frame associated with the noun _car_ your function will print the definition of the only core frame element _Vehicle_:\n",
        "\n",
        "\n",
        "> Vehicle is the transportation device that the human beings use to travel.This FE is incorporated into each LU in this frame.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7EdFxMeWhdOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printcoreFE(frame):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    frame: a frame object from FrameNet\n",
        "  \"\"\"\n",
        "  #your code here"
      ],
      "metadata": {
        "id": "cwp_SmRRflyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Test your function on the frame evoked by the verb _sing_:\n",
        "\n"
      ],
      "metadata": {
        "id": "fa_r8tEeiWtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n",
        "sing=\n",
        "\n",
        "printcoreFE(frame=sing)"
      ],
      "metadata": {
        "id": "hpCNSPF6gkpt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8df46d9eebb447a2a769f1663513f642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10c6d07969ec41818c37def420874ec8",
              "IPY_MODEL_b199f43c32c348e89d52d4d69169c538",
              "IPY_MODEL_dfb7c305b0544158b7c3d4736d0efa4b"
            ],
            "layout": "IPY_MODEL_f638dae70ccb4ca188c24f01e6aafe39"
          }
        },
        "10c6d07969ec41818c37def420874ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_189ea4728ad74064be53716062bdbf63",
            "placeholder": "​",
            "style": "IPY_MODEL_16b43ccf9b194bc3a1258a8b60228596",
            "value": "Training Epochs: 100%"
          }
        },
        "b199f43c32c348e89d52d4d69169c538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fc857d083af42dfa55f6ccd71dbf42c",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6338b38e7b75445bae9ff663ad3b31fa",
            "value": 20
          }
        },
        "dfb7c305b0544158b7c3d4736d0efa4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7149c822f87e41edb3d9da831fffdb84",
            "placeholder": "​",
            "style": "IPY_MODEL_27eceb26f78143b1a5ec7a3b39a02603",
            "value": " 20/20 [00:00&lt;00:00, 339.08it/s]"
          }
        },
        "f638dae70ccb4ca188c24f01e6aafe39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189ea4728ad74064be53716062bdbf63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b43ccf9b194bc3a1258a8b60228596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fc857d083af42dfa55f6ccd71dbf42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6338b38e7b75445bae9ff663ad3b31fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7149c822f87e41edb3d9da831fffdb84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27eceb26f78143b1a5ec7a3b39a02603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}