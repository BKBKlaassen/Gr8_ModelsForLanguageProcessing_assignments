{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BKBKlaassen/Gr8_ModelsForLanguageProcessing_assignments/blob/main/Group_8_Assignment_4_2026_student_b_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zydk5m0FpaKT"
      },
      "source": [
        "## Assignment 4\n",
        "\n",
        "In this assignment, you are asked to work with pretrained language models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Contributions</font>\n",
        "\n",
        "Group number: 8\n",
        "\n",
        "Group members: Bjorn Klaassen, Noah de Jonge\n",
        "\n",
        "Who contributed to which exercises (you don't need to be very detailed):"
      ],
      "metadata": {
        "id": "8rvH77dcj-2Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ledaEclUpvzT"
      },
      "source": [
        "In this assignment, you will work with pretrained language models. While they are small by modern standards, the computation required in the exercises below can be sped up if you use GPU for it. In the menu on Colab, go to \"Runtime > Change runtime type\" to enable GPU device (designated as `'cuda'` in the code).\n",
        "\n",
        "Google Colab offers limited GPU resources, which are sufficient for doing the entire assignment. However, if you debug your code by repeatedly running large amounts of GPU computation, you may run out of the GPU allocation provided by Google. One thing you should learn from this assignment is to use GPU compute strategically, debugging without a GPU or with reduced data or computation. (GPU resources are just as scarce in the 'real world', outside of the simple tasks we do in class: for example, there are open weight language models with advanced capabilities, such as DeepSeek-R1, that theoretically anyone can run, but in practice the hardware requirements are prohibitive.)\n",
        "\n",
        "If you do run out of GPU allocation on Colab, you can usually continue working in a different Google account as a workaround.\n",
        "\n",
        "To start the assignment, import prerequisite packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bRh6vltQpvTn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import nltk,sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "MM9Qv40viw_l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import collections, itertools\n",
        "import more_itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.1 BERT-like Model for Classification"
      ],
      "metadata": {
        "id": "hJh9S94-N_D1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dvw-UmFNO1Z"
      },
      "source": [
        "##4.1.1 SICK dataset\n",
        "\n",
        "In Assignment 2, we did entailment (hypernymy) classification on the basis of word vectors. Now we can do a similar experiment for sentence embeddings. Start by downloading the SICK dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "z3_ak3ugNNqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f709ea-8d78-4250-bf2a-7acadde943a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-25 15:25:04--  https://zenodo.org/record/2787612/files/SICK.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.52.235, 188.185.43.153, 188.184.103.118, ...\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.52.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/2787612/files/SICK.zip [following]\n",
            "--2026-02-25 15:25:05--  https://zenodo.org/records/2787612/files/SICK.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217584 (212K) [application/octet-stream]\n",
            "Saving to: ‘SICK.zip’\n",
            "\n",
            "SICK.zip            100%[===================>] 212.48K   341KB/s    in 0.6s    \n",
            "\n",
            "2026-02-25 15:25:07 (341 KB/s) - ‘SICK.zip’ saved [217584/217584]\n",
            "\n",
            "Archive:  SICK.zip\n",
            "replace readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/record/2787612/files/SICK.zip?download=1 -O SICK.zip\n",
        "!unzip SICK.zip\n",
        "!rm SICK.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4p8hLMOjN4AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8081624b-ebe7-4dd9-97eb-d59995e69f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pair_ID\tsentence_A\tsentence_B\tentailment_label\trelatedness_score\tentailment_AB\tentailment_BA\tsentence_A_original\tsentence_B_original\tsentence_A_dataset\tsentence_B_dataset\tSemEval_set\r\n",
            "1\tA group of kids is playing in a yard and an old man is standing in the background\tA group of boys in a yard is playing and a man is standing in the background\tNEUTRAL\t4.5\tA_neutral_B\tB_neutral_A\tA group of children playing in a yard, a man in the background.\tA group of children playing in a yard, a man in the background.\tFLICKR\tFLICKR\tTRAIN\r\n",
            "2\tA group of children is playing in the house and there is no man standing in the background\tA group of kids is playing in a yard and an old man is standing in the background\tNEUTRAL\t3.2\tA_contradicts_B\tB_neutral_A\tA group of children playing in a yard, a man in the background.\tA group of children playing in a yard, a man in the background.\tFLICKR\tFLICKR\tTRAIN\r\n",
            "3\tThe young boys are playing outdoors and the man is smiling nearby\tThe kids are playing outdoors near a man with a smile\tENTAILMENT\t4.7\tA_entails_B\tB_entails_A\tThe children are playing outdoors, while a man smiles nearby.\tThe children are playing outdoors, while a man smiles nearby.\tFLICKR\tFLICKR\tTRAIN\r\n",
            "4\tThe young boys are playing outdoors and the man is smiling nearby\tThere is no boy playing outdoors and there is no man smiling\tCONTRADICTION\t3.6\tA_contradicts_B\tB_contradicts_A\tThe children are playing outdoors, while a man smiles nearby.\tThe children are playing outdoors, while a man smiles nearby.\tFLICKR\tFLICKR\tTRIAL\r\n",
            "5\tThe kids are playing outdoors near a man with a smile\tA group of kids is playing in a yard and an old man is standing in the background\tNEUTRAL\t3.4\tA_neutral_B\tB_neutral_A\tA group of children playing in a yard, a man in the background.\tThe children are playing outdoors, while a man smiles nearby.\tFLICKR\tFLICKR\tTRAIN\r\n",
            "6\tThere is no boy playing outdoors and there is no man smiling\tA group of kids is playing in a yard and an old man is standing in the background\tNEUTRAL\t3.3\tA_neutral_B\tB_neutral_A\tA group of children playing in a yard, a man in the background.\tThe children are playing outdoors, while a man smiles nearby.\tFLICKR\tFLICKR\tTEST\r\n",
            "7\tA group of boys in a yard is playing and a man is standing in the background\tThe young boys are playing outdoors and the man is smiling nearby\tNEUTRAL\t3.7\tA_neutral_B\tB_neutral_A\tThe children are playing outdoors, while a man smiles nearby.\tA group of children playing in a yard, a man in the background.\tFLICKR\tFLICKR\tTEST\r\n",
            "8\tA group of children is playing in the house and there is no man standing in the background\tThe young boys are playing outdoors and the man is smiling nearby\tNEUTRAL\t3\tA_neutral_B\tB_contradicts_A\tThe children are playing outdoors, while a man smiles nearby.\tA group of children playing in a yard, a man in the background.\tFLICKR\tFLICKR\tTEST\r\n",
            "9\tThe young boys are playing outdoors and the man is smiling nearby\tA group of kids is playing in a yard and an old man is standing in the background\tNEUTRAL\t3.7\tA_neutral_B\tB_neutral_A\tA group of children playing in a yard, a man in the background.\tThe children are playing outdoors, while a man smiles nearby.\tFLICKR\tFLICKR\tTRAIN\r\n"
          ]
        }
      ],
      "source": [
        "!head SICK.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ymPQ1m3yOSJg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "sick_df = pd.read_csv('SICK.txt', sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can inspect the first few data entries of the SICK dataset. You will see sentence A and sentence B and the entailment_labels, indicating whether sentence A entails sentence B."
      ],
      "metadata": {
        "id": "8D5_KfPsLPER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sick_df"
      ],
      "metadata": {
        "id": "ZUrGFDUXLIpD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "7c6241ec-2cfb-4167-eb9f-e80107f8914c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      pair_ID                                         sentence_A  \\\n",
              "0           1  A group of kids is playing in a yard and an ol...   \n",
              "1           2  A group of children is playing in the house an...   \n",
              "2           3  The young boys are playing outdoors and the ma...   \n",
              "3           4  The young boys are playing outdoors and the ma...   \n",
              "4           5  The kids are playing outdoors near a man with ...   \n",
              "...       ...                                                ...   \n",
              "9835     9996  A man is in a parking lot and is playing tenni...   \n",
              "9836     9997                   Someone is boiling okra in a pot   \n",
              "9837     9998  The man is singing heartily and playing the gu...   \n",
              "9838     9999        A man in blue has a yellow ball in the mitt   \n",
              "9839    10000               Three dogs are resting on a sidewalk   \n",
              "\n",
              "                                             sentence_B entailment_label  \\\n",
              "0     A group of boys in a yard is playing and a man...          NEUTRAL   \n",
              "1     A group of kids is playing in a yard and an ol...          NEUTRAL   \n",
              "2     The kids are playing outdoors near a man with ...       ENTAILMENT   \n",
              "3     There is no boy playing outdoors and there is ...    CONTRADICTION   \n",
              "4     A group of kids is playing in a yard and an ol...          NEUTRAL   \n",
              "...                                                 ...              ...   \n",
              "9835  The snowboarder is leaping fearlessly over whi...          NEUTRAL   \n",
              "9836                   The man is not playing the drums          NEUTRAL   \n",
              "9837  A bicyclist is holding a bike over his head in...          NEUTRAL   \n",
              "9838                      A man is jumping rope outside          NEUTRAL   \n",
              "9839         The woman with a knife is slicing a pepper          NEUTRAL   \n",
              "\n",
              "      relatedness_score    entailment_AB    entailment_BA  \\\n",
              "0                   4.5      A_neutral_B      B_neutral_A   \n",
              "1                   3.2  A_contradicts_B      B_neutral_A   \n",
              "2                   4.7      A_entails_B      B_entails_A   \n",
              "3                   3.6  A_contradicts_B  B_contradicts_A   \n",
              "4                   3.4      A_neutral_B      B_neutral_A   \n",
              "...                 ...              ...              ...   \n",
              "9835                1.0      A_neutral_B      B_neutral_A   \n",
              "9836                1.0      A_neutral_B      B_neutral_A   \n",
              "9837                1.0      A_neutral_B      B_neutral_A   \n",
              "9838                1.2      A_neutral_B      B_neutral_A   \n",
              "9839                1.0      A_neutral_B      B_neutral_A   \n",
              "\n",
              "                                    sentence_A_original  \\\n",
              "0     A group of children playing in a yard, a man i...   \n",
              "1     A group of children playing in a yard, a man i...   \n",
              "2     The children are playing outdoors, while a man...   \n",
              "3     The children are playing outdoors, while a man...   \n",
              "4     A group of children playing in a yard, a man i...   \n",
              "...                                                 ...   \n",
              "9835  A man is playing tennis with himself against a...   \n",
              "9836                   someone is boiling okra in a pot   \n",
              "9837                 the man sang and played his guitar   \n",
              "9838                      a man is jumping rope outside   \n",
              "9839           a woman with a knife is slicing a pepper   \n",
              "\n",
              "                                    sentence_B_original sentence_A_dataset  \\\n",
              "0     A group of children playing in a yard, a man i...             FLICKR   \n",
              "1     A group of children playing in a yard, a man i...             FLICKR   \n",
              "2     The children are playing outdoors, while a man...             FLICKR   \n",
              "3     The children are playing outdoors, while a man...             FLICKR   \n",
              "4     The children are playing outdoors, while a man...             FLICKR   \n",
              "...                                                 ...                ...   \n",
              "9835  A snowboarder launches into the air over white...             FLICKR   \n",
              "9836                       the man is playing the drums            SEMEVAL   \n",
              "9837  a bicyclist holds their bike over their head b...            SEMEVAL   \n",
              "9838      a woman in blue has a yellow ball in her mitt            SEMEVAL   \n",
              "9839                           three dogs on a sidewalk            SEMEVAL   \n",
              "\n",
              "     sentence_B_dataset SemEval_set  \n",
              "0                FLICKR       TRAIN  \n",
              "1                FLICKR       TRAIN  \n",
              "2                FLICKR       TRAIN  \n",
              "3                FLICKR       TRIAL  \n",
              "4                FLICKR       TRAIN  \n",
              "...                 ...         ...  \n",
              "9835             FLICKR        TEST  \n",
              "9836            SEMEVAL       TRAIN  \n",
              "9837             FLICKR       TRAIN  \n",
              "9838             FLICKR       TRAIN  \n",
              "9839             FLICKR       TRAIN  \n",
              "\n",
              "[9840 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8454a269-0b8f-4ed3-aeb6-26f4e320dd51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pair_ID</th>\n",
              "      <th>sentence_A</th>\n",
              "      <th>sentence_B</th>\n",
              "      <th>entailment_label</th>\n",
              "      <th>relatedness_score</th>\n",
              "      <th>entailment_AB</th>\n",
              "      <th>entailment_BA</th>\n",
              "      <th>sentence_A_original</th>\n",
              "      <th>sentence_B_original</th>\n",
              "      <th>sentence_A_dataset</th>\n",
              "      <th>sentence_B_dataset</th>\n",
              "      <th>SemEval_set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>A group of boys in a yard is playing and a man...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>4.5</td>\n",
              "      <td>A_neutral_B</td>\n",
              "      <td>B_neutral_A</td>\n",
              "      <td>A group of children playing in a yard, a man i...</td>\n",
              "      <td>A group of children playing in a yard, a man i...</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>A group of children is playing in the house an...</td>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>3.2</td>\n",
              "      <td>A_contradicts_B</td>\n",
              "      <td>B_neutral_A</td>\n",
              "      <td>A group of children playing in a yard, a man i...</td>\n",
              "      <td>A group of children playing in a yard, a man i...</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>The young boys are playing outdoors and the ma...</td>\n",
              "      <td>The kids are playing outdoors near a man with ...</td>\n",
              "      <td>ENTAILMENT</td>\n",
              "      <td>4.7</td>\n",
              "      <td>A_entails_B</td>\n",
              "      <td>B_entails_A</td>\n",
              "      <td>The children are playing outdoors, while a man...</td>\n",
              "      <td>The children are playing outdoors, while a man...</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>The young boys are playing outdoors and the ma...</td>\n",
              "      <td>There is no boy playing outdoors and there is ...</td>\n",
              "      <td>CONTRADICTION</td>\n",
              "      <td>3.6</td>\n",
              "      <td>A_contradicts_B</td>\n",
              "      <td>B_contradicts_A</td>\n",
              "      <td>The children are playing outdoors, while a man...</td>\n",
              "      <td>The children are playing outdoors, while a man...</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TRIAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>The kids are playing outdoors near a man with ...</td>\n",
              "      <td>A group of kids is playing in a yard and an ol...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>3.4</td>\n",
              "      <td>A_neutral_B</td>\n",
              "      <td>B_neutral_A</td>\n",
              "      <td>A group of children playing in a yard, a man i...</td>\n",
              "      <td>The children are playing outdoors, while a man...</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9835</th>\n",
              "      <td>9996</td>\n",
              "      <td>A man is in a parking lot and is playing tenni...</td>\n",
              "      <td>The snowboarder is leaping fearlessly over whi...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>A_neutral_B</td>\n",
              "      <td>B_neutral_A</td>\n",
              "      <td>A man is playing tennis with himself against a...</td>\n",
              "      <td>A snowboarder launches into the air over white...</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TEST</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9836</th>\n",
              "      <td>9997</td>\n",
              "      <td>Someone is boiling okra in a pot</td>\n",
              "      <td>The man is not playing the drums</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>A_neutral_B</td>\n",
              "      <td>B_neutral_A</td>\n",
              "      <td>someone is boiling okra in a pot</td>\n",
              "      <td>the man is playing the drums</td>\n",
              "      <td>SEMEVAL</td>\n",
              "      <td>SEMEVAL</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9837</th>\n",
              "      <td>9998</td>\n",
              "      <td>The man is singing heartily and playing the gu...</td>\n",
              "      <td>A bicyclist is holding a bike over his head in...</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>A_neutral_B</td>\n",
              "      <td>B_neutral_A</td>\n",
              "      <td>the man sang and played his guitar</td>\n",
              "      <td>a bicyclist holds their bike over their head b...</td>\n",
              "      <td>SEMEVAL</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9838</th>\n",
              "      <td>9999</td>\n",
              "      <td>A man in blue has a yellow ball in the mitt</td>\n",
              "      <td>A man is jumping rope outside</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>1.2</td>\n",
              "      <td>A_neutral_B</td>\n",
              "      <td>B_neutral_A</td>\n",
              "      <td>a man is jumping rope outside</td>\n",
              "      <td>a woman in blue has a yellow ball in her mitt</td>\n",
              "      <td>SEMEVAL</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9839</th>\n",
              "      <td>10000</td>\n",
              "      <td>Three dogs are resting on a sidewalk</td>\n",
              "      <td>The woman with a knife is slicing a pepper</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>1.0</td>\n",
              "      <td>A_neutral_B</td>\n",
              "      <td>B_neutral_A</td>\n",
              "      <td>a woman with a knife is slicing a pepper</td>\n",
              "      <td>three dogs on a sidewalk</td>\n",
              "      <td>SEMEVAL</td>\n",
              "      <td>FLICKR</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9840 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8454a269-0b8f-4ed3-aeb6-26f4e320dd51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8454a269-0b8f-4ed3-aeb6-26f4e320dd51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8454a269-0b8f-4ed3-aeb6-26f4e320dd51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_72a91094-a9ca-4fc2-bea1-aab3f321ce7b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sick_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_72a91094-a9ca-4fc2-bea1-aab3f321ce7b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sick_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sick_df",
              "summary": "{\n  \"name\": \"sick_df\",\n  \"rows\": 9840,\n  \"fields\": [\n    {\n      \"column\": \"pair_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2898,\n        \"min\": 1,\n        \"max\": 10000,\n        \"num_unique_values\": 9840,\n        \"samples\": [\n          6957,\n          7273,\n          107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5013,\n        \"samples\": [\n          \"A small black and white dog is carrying a stick and is swimming\",\n          \"Some water is being drunk by a cat\",\n          \"A little boy is wearing a yellow tank top and is laughing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_B\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4945,\n        \"samples\": [\n          \"A bald person is playing a guitar\",\n          \"The man is playing a piano\",\n          \"There is no woman dancing and singing in the rain\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entailment_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"NEUTRAL\",\n          \"ENTAILMENT\",\n          \"CONTRADICTION\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relatedness_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0170495675731468,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 173,\n        \"samples\": [\n          4.915,\n          3.55,\n          1.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entailment_AB\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"A_neutral_B\",\n          \"A_contradicts_B\",\n          \"A_entails_B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entailment_BA\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"B_neutral_A\",\n          \"B_entails_A\",\n          \"B_contradicts_A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_A_original\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1903,\n        \"samples\": [\n          \"a bicyclist is jumping on a pyramid-shaped ramp\",\n          \"A gorup of boys are playing with a ball in front of a large wooden door.\",\n          \"the man sang on stage into the microphone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_B_original\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1907,\n        \"samples\": [\n          \"two young men play outside near a golden statue of ghandi\",\n          \"A white and brown dog is walking through the water.\",\n          \"a dog jumping high into the air in the country\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_A_dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"SEMEVAL\",\n          \"FLICKR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_B_dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"SEMEVAL\",\n          \"FLICKR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SemEval_set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"TRAIN\",\n          \"TRIAL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibP-oQUPLds5"
      },
      "source": [
        "Read the train and test data from the file. Be sure to include in the training data all sentence pairs marked as \"train\" or \"trial\" in the SICK.txt file, and in the test data all sentence pairs marked as \"test\". As labels, use values from the `entailment_label` column in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "a2Xs-Op5MARu"
      },
      "outputs": [],
      "source": [
        "sick_train_examples=[]\n",
        "sick_test_examples=[]\n",
        "sick_train_labels=[]\n",
        "sick_test_labels=[]\n",
        "\n",
        "for i in range(len(sick_df)):\n",
        "  if(sick_df.SemEval_set[i] == \"TRAIN\" or sick_df.SemEval_set[i] == \"TRIAL\"):\n",
        "    sick_train_examples.append((sick_df.sentence_A[i],sick_df.sentence_B[i]))\n",
        "    sick_train_labels.append(sick_df.entailment_label[i])\n",
        "  elif(sick_df.SemEval_set[i] == \"TEST\"):\n",
        "    sick_test_examples.append((sick_df.sentence_A[i],sick_df.sentence_B[i]))\n",
        "    sick_test_labels.append(sick_df.entailment_label[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check how many examples and label you have got in each partition:"
      ],
      "metadata": {
        "id": "RJLeZDgD44Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sick_train_examples),len(sick_train_labels),len(sick_test_examples),len(sick_test_labels))"
      ],
      "metadata": {
        "id": "rXO8jKhP4pBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c564e03d-af78-4520-c53f-e0a4d0f2d20b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4934 4934 4906 4906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtfHcBiTMJ5u"
      },
      "source": [
        "##4.1.2. Use a pretrained language model for sequence embedding\n",
        "\n",
        "We can rely here on Huggingface which provides many pretrained models in its ```transformers``` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "7p1UrqEzPC93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2ddf07-226d-41b2-aff5-267f28138acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.24.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjYHth0_TlRR"
      },
      "source": [
        "Here we can use a relatively small BERT-like model called DistilBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SU3yssk9OzAx"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AfU2rXewQRUY"
      },
      "outputs": [],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert-base-uncased\",padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Fy1BmIpBQXVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250,
          "referenced_widgets": [
            "eb0b15a705864413a7553bd73d11424d",
            "ff85caa5b457445788f699842b10812d",
            "a950c6e1619d4c8cade0e2b3df97aeab",
            "c2a6d5975448415b848f78c33bdc4f2e",
            "64e99903f4cc40638247dbeb5d9ed826",
            "8fca2cbcf1eb4b9188beb7308420fb7c",
            "776cf098b8624bfca87979740f55df88",
            "7b3699ea547045f89dbab006593ecf0a",
            "f069fd16e9684d9f9fc94e4cc6659433",
            "3689431718d84cf9a7e60e4d1072fb9f",
            "d49936b02b3445b7b10a26e11ca12041"
          ]
        },
        "outputId": "a1356e38-936d-48ae-d09e-4737202f7a09"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb0b15a705864413a7553bd73d11424d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DistilBertModel LOAD REPORT from: distilbert-base-uncased\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "vocab_projector.bias    | UNEXPECTED |  | \n",
            "vocab_transform.bias    | UNEXPECTED |  | \n",
            "vocab_layer_norm.weight | UNEXPECTED |  | \n",
            "vocab_transform.weight  | UNEXPECTED |  | \n",
            "vocab_layer_norm.bias   | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        }
      ],
      "source": [
        "distilbert = transformers.AutoModel.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGVTP6HrUOy0"
      },
      "source": [
        "Tokeniser of the model does a lot of heavy lifting. It takes in a sentence or a pair of sentences, concatenates them, tokenizes, adds [CLS] token (id: 101) and separator(s) [SEP] token (id: 102) and returns a nensor with the list of token ids:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "nZY0g2nqQoqH"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(sick_df.sentence_A.tolist()[5],sick_df.sentence_B.tolist()[5], return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "y7Pxg96gQumI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7623a688-1e26-4576-8242-c10c647da7bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2045,  2003,  2053,  2879,  2652, 19350,  1998,  2045,  2003,\n",
            "          2053,  2158,  5629,   102,  1037,  2177,  1997,  4268,  2003,  2652,\n",
            "          1999,  1037,  4220,  1998,  2019,  2214,  2158,  2003,  3061,  1999,\n",
            "          1996,  4281,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many tokens does the tokenizer recognise in sentences A and B in the example above?\n",
        "\n",
        "__Answer:__\n",
        "\n",
        "Not including the CLS token,\n",
        "\n",
        "Sentence A: 13 tokens\n",
        "\n",
        "Sentence B: 19 tokens\n",
        "\n",
        "Together: 32 tokens\n",
        "\n",
        "Together + CLS token: 33 Tokens"
      ],
      "metadata": {
        "id": "5hsvqob3HhJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The token IDs can be decoded back into strings, for example:"
      ],
      "metadata": {
        "id": "Z2UJydk3M0SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "for id, token in zip(inputs['input_ids'][0], tokens):\n",
        "    print(f\"{id.item():5d} → {token}\")"
      ],
      "metadata": {
        "id": "DZ5aAzLIMv5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09b3107-ac1d-4e27-ceb4-39a6d8687757"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  101 → [CLS]\n",
            " 2045 → there\n",
            " 2003 → is\n",
            " 2053 → no\n",
            " 2879 → boy\n",
            " 2652 → playing\n",
            "19350 → outdoors\n",
            " 1998 → and\n",
            " 2045 → there\n",
            " 2003 → is\n",
            " 2053 → no\n",
            " 2158 → man\n",
            " 5629 → smiling\n",
            "  102 → [SEP]\n",
            " 1037 → a\n",
            " 2177 → group\n",
            " 1997 → of\n",
            " 4268 → kids\n",
            " 2003 → is\n",
            " 2652 → playing\n",
            " 1999 → in\n",
            " 1037 → a\n",
            " 4220 → yard\n",
            " 1998 → and\n",
            " 2019 → an\n",
            " 2214 → old\n",
            " 2158 → man\n",
            " 2003 → is\n",
            " 3061 → standing\n",
            " 1999 → in\n",
            " 1996 → the\n",
            " 4281 → background\n",
            "  102 → [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whRaY6yOUzSd"
      },
      "source": [
        "Now we can pass the tensor output of the tokenizer through the model, getting its hidden states:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Y1msn3ZhQ6Cv"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    output = distilbert(**inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz4UyRT7Hq8G"
      },
      "source": [
        "Above, ```torch.no_grad()``` guarantees that no gradients are computed in this code block. So the model's weights cannot be updated. This is what we want now: obtain sentence pair vectors from the model, without making any changes to the model itself.\n",
        "\n",
        "You should use ```output.last_hidden_state``` that stores the last hidden layer. From that, you only need the first vector, which corresponds to the [CLS] token. It is the first in the sequence so has index 0.\n",
        "\n",
        "**Exercise**. What is the size of that vector? Check!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "OUzkfHglRBIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353239bb-7ea3-4b2d-a668-b5182176e9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        }
      ],
      "source": [
        "#your code\n",
        "print(len(output.last_hidden_state[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBOKubHp1Qhi"
      },
      "source": [
        "Now we can define linear regression model in pyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "h1AxCRLH1Qho"
      },
      "outputs": [],
      "source": [
        "class Regression(torch.nn.Module):\n",
        "  def __init__(self, input_dim,output_dim):\n",
        "    super(Regression,self).__init__()\n",
        "    self.linear = torch.nn.Linear(input_dim,output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    outputs = self.linear(x)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19SEdasaU8pS"
      },
      "source": [
        "It is the last vector of the [CLS] token that is normally used for sequence classification with BERT models. Train and test a logistic regression classifier on top of (frozen) DistilBERT embeddings for sentence pairs in SICK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "_wUo0J_FPfr5"
      },
      "outputs": [],
      "source": [
        "distilbert_embdim = distilbert.config.hidden_size\n",
        "\n",
        "entailment_model = Regression(distilbert_embdim,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Define loss and initialize an optimizer:"
      ],
      "metadata": {
        "id": "xQu_BD_m5ROD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(entailment_model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "sRMboxJ45Qkh",
        "outputId": "7536344e-b1f7-46b1-d28a-24ed89b9d692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2904551414.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentailment_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4yKLr-mPAMB"
      },
      "source": [
        "Now prepare the data: convert ```sick_train_examples``` and ```sick_test_examples``` into lists of torch tesors (embeddings of the sentence pairs).\n",
        "\n",
        "__Hint__: to speed up neural computation, it can be helpful to move data and model to the GPU, a special processor that handles numeric tensor operations more efficiently (you may use commands like ```model.to('cuda')```, ```tensordata.to('cuda')```). For further non-neural computation, data can be moved back to the CPU ```tensordata.to('cpu')```. In case you (temporarily) don't have access to a GPU, you can use `'cpu'` instead of `'cuda'` to do the computation on a CPU. However, this will slow the computation down.\n",
        "\n",
        "Processing all the sentence pairs in pretrained DistilBERT will take a couple of minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "i8lSYoD3PA-v"
      },
      "outputs": [],
      "source": [
        "#enabling GPU computation\n",
        "distilbert.to('cuda')\n",
        "\n",
        "sick_train_examples = [tokenizer(sentencePair[0],sentencePair[1], return_tensors=\"pt\") for sentencePair in sick_train_examples]\n",
        "sick_test_examples = [tokenizer(sentencePair[0],sentencePair[1], return_tensors=\"pt\") for sentencePair in sick_test_examples]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, convert ```sick_train_labels``` and ```sick_test_labels``` into lists of indices:"
      ],
      "metadata": {
        "id": "qCS7LpM_5yBA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "KDxP2-K_WKpy"
      },
      "outputs": [],
      "source": [
        "sick_train_labels_idx= [i for i in range(len(sick_train_labels))]\n",
        "sick_test_labels_idx= [i for i in range(len(sick_test_labels))]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Train for 40 epochs and test a regression model on DistilBERT embeddings to classify SICK with the three entailment labels. Print out train and test accuracy and loss every 5 epochs."
      ],
      "metadata": {
        "id": "p-i1Gwpc6FUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFpESTU_Gz7P"
      },
      "outputs": [],
      "source": [
        "epochs=40\n",
        "#accuracy\n",
        "def accuracy(predictions, scores):\n",
        "  score = 0\n",
        "  for i in range(0,len(predictions)):\n",
        "    if predictions[i] == scores[i]:\n",
        "      score +=1\n",
        "  return score / len(scores)\n",
        "\n",
        "# training model\n",
        "for epoch in trange(epochs):\n",
        "\n",
        "  if(epoch+1) % 5 ==0:\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwQdUS8-VVGY"
      },
      "source": [
        "##4.1.3 Fine-tuning\n",
        "\n",
        "Can you improve the performance of entailment classification even further?\n",
        "\n",
        "_Fine-tune_ DistilBERT on the task: train and test a logistic regression classifier on top of DistilBERT embeddings for sentence pairs in SICK while updating the model weights. Define a new model class that combines DistilBERT and regression models into a single model, which passes sentence pair input through DistilBERT and uses the output embedding of the CLS token as input to regression, which finally produces the output of the whole combined model.\n",
        "\n",
        "The weights of this bigger model (i.e. both DistilBERT weights and regression weights) can then be updated by the optimizer.\n",
        "\n",
        "**Exercise**. Train the whole pipeline for 4 epochs using the train/test split as above.\n",
        "\n",
        "For this last exercise, using a GPU is essential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czdFkcOcVm5Y"
      },
      "outputs": [],
      "source": [
        "epochs = 4\n",
        "#your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.2 Autoregressive Transformer (GPT2)"
      ],
      "metadata": {
        "id": "cPM31NVnN2cs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.2.1 Text generation with GPT2\n"
      ],
      "metadata": {
        "id": "xEG4PBS339kF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will load and use the smallest version of GPT2 to save time and resources; it suffices for our purposes."
      ],
      "metadata": {
        "id": "fK6JDVdQakmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "hXo_t8-dc9qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To put GPT-2 to a test, we can create a list of examples as text snippets that GPT-2 is then asked to complete. We use three simple prompts here, taken from the beginning of NL Times articles in 2024."
      ],
      "metadata": {
        "id": "B9it3ASiZqal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts=[\n",
        "    \"The Schoof I Cabinet will likely have fewer Ministers and State Secretaries than the outgoing Rutte IV Cabinet, sources close to the formation process told the Telegraaf.\",\n",
        "    \"Outgoing Agriculture Minister Piet Adema wants to ban business of yoga sessions that also involve puppies. Puppy yoga has been offered in Amsterdam for months now.\",\n",
        "    \"The Walt Disney Company will participate in the Pride boat parade in the Netherlands for the first time on Saturday. \"]"
      ],
      "metadata": {
        "id": "eQ0v4S64Xn8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**. Define functions ```run_on_prompt``` and ```run_on_prompts```. ```run_on_prompt``` takes a sting prompt and returns a list of n continuations of the prompt. ```run_on_prompts``` that takes a list of prompts and returns a list of lists of n continuations of each prompt.\n",
        "Schematically, `run_on_prompts([prompt1,prompt2],nsamples=2)` should output `[[continuation1OfPrompt1,continuation2OfPrompt1],[continuation1OfPrompt2,continuation1OfPrompt2]]`.\n",
        "\n",
        "*  Make sure your functions contain the `temperature` and `top_p` sampling parameters as you will be asked to experiment with them.\n",
        "*  Your ```run_on_prompt``` function should also print the prompt and generated text continuations so you can inspect them.\n",
        "*  Make sure that the outputs produced by ```run_on_prompt``` do not contain the prompt itself.\n",
        "\n",
        "**Hints:**\n",
        "* You'll need to use both the tokenizer and the model's generate() method. Look up the necessary details in the Hugging Face text [generation documentation](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation) and the [reference on generation strategies](https://huggingface.co/docs/transformers/generation_strategies).\n",
        "* To extract just the continuation, compare the length of the original prompt to the generated text."
      ],
      "metadata": {
        "id": "oq3V_aT74apP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set padding token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "\n",
        "def run_on_prompt(model, prompt, nsamples=3, length=1,\n",
        "                   temperature=1,\n",
        "                   top_k=None,\n",
        "                   top_p=1):\n",
        "    \"\"\"\n",
        "    Generates text continuations for a single prompt using a GPT model.\n",
        "\n",
        "    Args:\n",
        "        model: GPT model instance.\n",
        "        prompt: A string prompt.\n",
        "        nsamples: The number of samples to generate for the prompt.\n",
        "        length: The maximum length of new tokens to generate.\n",
        "        temperature: Temperature parameter for controlling randomness.\n",
        "        top_k: Top-k sampling parameter.\n",
        "        top_p: Top-p (nucleus) sampling parameter.\n",
        "\n",
        "    Returns:\n",
        "        A list of generated text continuations (without the prompt).\n",
        "    \"\"\"\n",
        "    #your code here\n",
        "\n",
        "\n",
        "def run_on_prompts(model, prompt_list, nsamples=3, length=1,\n",
        "                   temperature=1,\n",
        "                   top_k=None,\n",
        "                   top_p=1):\n",
        "    \"\"\"\n",
        "    Generates text continuations for a list of prompts using a GPT model.\n",
        "\n",
        "    Args:\n",
        "        model: GPT model instance.\n",
        "        prompt_list: A list of strings, where each string is a prompt.\n",
        "        nsamples: The number of samples to generate for each prompt.\n",
        "        length: The maximum length of new tokens to generate.\n",
        "        temperature: Temperature parameter for controlling randomness.\n",
        "        top_k: Top-k sampling parameter.\n",
        "        top_p: Top-p (nucleus) sampling parameter.\n",
        "\n",
        "    Returns:\n",
        "        A list of lists, where each inner list contains continuations for one prompt.\n",
        "    \"\"\"\n",
        "    #your code here"
      ],
      "metadata": {
        "id": "wsUIstpReBY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run GPT-2 with your function with different temperature values: 0.4 (low), 0.8,  1 (default) and 2 (high). Extreme values are suggested for pedagogical purposes."
      ],
      "metadata": {
        "id": "qoPvx9I1SO9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "gptsmall = model.to(device)\n",
        "temp04outputs=run_on_prompts(gptsmall,prompts, length=100, temperature=0.4)"
      ],
      "metadata": {
        "id": "uMORuh2RDQmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp08outputs=run_on_prompts(gptsmall,prompts, length=100, temperature=0.8)"
      ],
      "metadata": {
        "id": "XO9a_r6DKNEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp1outputs=run_on_prompts(gptsmall,prompts, length=100, temperature=1)"
      ],
      "metadata": {
        "id": "qyZ0Bv-DR7Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp2outputs=run_on_prompts(gptsmall,prompts, length=100, temperature=2.0)"
      ],
      "metadata": {
        "id": "0p67DEzpONLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the generated texts. What are your observations about the role of temperature?\n",
        "\n",
        "**Answer**:\n",
        "YOUR ANSWER HERE"
      ],
      "metadata": {
        "id": "HYX5luA8armM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now keep the temperature at default and run text generation with nucleus sampling (p-sampling) with p at 0.2, 0.3, 0.5, and 0.95."
      ],
      "metadata": {
        "id": "_Ug8EZaeTj0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputsp2=run_on_prompts(gptsmall,prompts, length=100,top_p=0.2)"
      ],
      "metadata": {
        "id": "iP-nrYddJ9AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputsp3=run_on_prompts(gptsmall,prompts, length=100,top_p=0.3)"
      ],
      "metadata": {
        "id": "NynZ_BoXCTZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputsp5=run_on_prompts(gptsmall,prompts, length=100,top_p=0.5)"
      ],
      "metadata": {
        "id": "rF53maw5GSgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputsp95=run_on_prompts(gptsmall,prompts, length=100,top_p=0.95)"
      ],
      "metadata": {
        "id": "qennf_ybCb2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are your observations on the outputs at different values of p?\n",
        "\n",
        "**Answer**\n",
        "YOUR ANSWER HERE"
      ],
      "metadata": {
        "id": "0y21AYKtUJ0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.2.2 Automatic measuring of text diversity"
      ],
      "metadata": {
        "id": "8L3etr0E_IP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You made some qualitative observartions on the output. Can we also identify quantitative differences between the generated texts? One approach is to measure the fraction of unique fragments (e.g. words or word sequences) in text.\n",
        "\n",
        "Define a function `uniqN` that takes a string `ss` and returns the proportion of unique token n-grams of length `n`. For simplicity, separate the string into words using `split()`."
      ],
      "metadata": {
        "id": "6jNDNy6l_tH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def uniqN(ss,n):\n",
        "  #YOUR CODE HERE"
      ],
      "metadata": {
        "id": "2D4iVVLPHWN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now define a function `avgrepN` which measures the diversity of text in an input corpus `c` (a list of lists of strings), returning the average `uniqN` value for each string in the corpus for n-grams ranging from length 1 to `maxn`. High values mean the texts are diverse, low values indicate a lot of repeating n-grams."
      ],
      "metadata": {
        "id": "WsmhrkCwXJGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avgrepN(c,maxn=3):\n",
        "  #YOUR CODE HERE"
      ],
      "metadata": {
        "id": "YbqhJwO7JB1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the average diversity for texts generated with diverse values of p under nucleus sampling."
      ],
      "metadata": {
        "id": "UDe9PcDyXvpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(avgrepN(outputsp2))\n",
        "print(avgrepN(outputsp3))\n",
        "print(avgrepN(outputsp5))\n",
        "print(avgrepN(outputsp95))\n"
      ],
      "metadata": {
        "id": "FStVQEL4Jgfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the average diversity for texts generated with diverse values of temperature."
      ],
      "metadata": {
        "id": "I7fm7FsYYkxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(avgrepN(temp04outputs))\n",
        "print(avgrepN(temp08outputs))\n",
        "print(avgrepN(temp1outputs))\n",
        "print(avgrepN(temp2outputs))"
      ],
      "metadata": {
        "id": "QfVfNxYtPCGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can compare the GPT2-generated outputs with reference texts, i.e. continuations of the prompts in the actual texts."
      ],
      "metadata": {
        "id": "U45EL_McZEQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REFERENCE1='''These types of lessons involve young dogs running around that the participants can cuddle after the lesson.\n",
        "Adema said he does not believe it is healthy for the young animals. \\\"I don't think that is suitable. Puppies need to sleep. They are at a very early stage of their development,\\\" he stated after the regular weekly Cabinet meeting.\n",
        "\\\"It serves no purpose at all and makes no sense. It really has to stop.\\\" He is preparing a draft proposal of the ban so that his replacement in the next Cabinet can implement it.\n",
        "'''\n",
        "REFERENCE2='''The Schoof I Cabinet will likely have fewer Ministers and State Secretaries than the outgoing Rutte IV Cabinet, sources close to the formation process told the Telegraaf. As the intended Prime Minister Dick Schoof is considered “party-less” and represents all four parties in the coalition, the Cabinet will likely have four Deputy Prime Ministers - one each from the PVV, VVD, NSC, and BBB.\n",
        "Schoof was sparing with information after his first formation session. '\\“It was a beautiful day,\\” he told the press after meeting with the leaders of the coalition parties and formateur Richard van Zwol.\n",
        "'''\n",
        "\n",
        "REFERENCE3='''The employees are taking part in the initiative of a company working group that promotes inclusion.\n",
        "Disney has increasingly focused on inclusion in recent years. Pride Walks have already taken place in London, Berlin, and Paris. However, this is the first time that the company has taken such a clear stand and made such a visible statement during a Dutch Pride. \"We are very pleased with the great interest and diversity of registrations for this year's boat parade,\" said the Utrecht Pride organization. \\\"The selected boats show what Utrecht Pride stands for, making the LGBTIQ+ community visible in all its facets, and we look forward to everyone enjoying this beautiful event, both on the water and along the side.\\\"'''"
      ],
      "metadata": {
        "id": "tpAwKDeVLTrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(avgrepN([[REFERENCE1],[REFERENCE2],[REFERENCE3]]))"
      ],
      "metadata": {
        "id": "Ief3nVB6Lboj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do the reference texts compare to texts generated under different values of p or temperature?\n",
        "\n",
        "**Answer**\n",
        "YOUR ANSWER HERE"
      ],
      "metadata": {
        "id": "FWPyXG26Ze4s"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb0b15a705864413a7553bd73d11424d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff85caa5b457445788f699842b10812d",
              "IPY_MODEL_a950c6e1619d4c8cade0e2b3df97aeab",
              "IPY_MODEL_c2a6d5975448415b848f78c33bdc4f2e"
            ],
            "layout": "IPY_MODEL_64e99903f4cc40638247dbeb5d9ed826"
          }
        },
        "ff85caa5b457445788f699842b10812d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fca2cbcf1eb4b9188beb7308420fb7c",
            "placeholder": "​",
            "style": "IPY_MODEL_776cf098b8624bfca87979740f55df88",
            "value": "Loading weights: 100%"
          }
        },
        "a950c6e1619d4c8cade0e2b3df97aeab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3699ea547045f89dbab006593ecf0a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f069fd16e9684d9f9fc94e4cc6659433",
            "value": 100
          }
        },
        "c2a6d5975448415b848f78c33bdc4f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3689431718d84cf9a7e60e4d1072fb9f",
            "placeholder": "​",
            "style": "IPY_MODEL_d49936b02b3445b7b10a26e11ca12041",
            "value": " 100/100 [00:00&lt;00:00, 263.81it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "64e99903f4cc40638247dbeb5d9ed826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fca2cbcf1eb4b9188beb7308420fb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776cf098b8624bfca87979740f55df88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b3699ea547045f89dbab006593ecf0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f069fd16e9684d9f9fc94e4cc6659433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3689431718d84cf9a7e60e4d1072fb9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49936b02b3445b7b10a26e11ca12041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}